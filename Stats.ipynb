{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8591cf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 3.0.1 requires huggingface-hub>=0.15.1, but you have huggingface-hub 0.10.1 which is incompatible.\n",
      "sentence-transformers 3.0.1 requires transformers<5.0.0,>=4.34.0, but you have transformers 4.20.1 which is incompatible.\n",
      "spacy 3.3.3 requires typing-extensions<4.6.0,>=3.7.4.1, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "spacy-transformers 1.3.5 requires spacy<4.1.0,>=3.5.0, but you have spacy 3.3.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-docx in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (9.5.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed typing-extensions-4.12.2\n",
      "Requirement already satisfied: spacy_transformers in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.5)\n",
      "Collecting spacy<4.1.0,>=3.5.0 (from spacy_transformers)\n",
      "  Using cached spacy-3.7.5-cp310-cp310-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: transformers<4.37.0,>=3.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy_transformers) (4.20.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy_transformers) (1.12.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy_transformers) (2.4.8)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy_transformers) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy_transformers) (1.23.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.0.9)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<4.1.0,>=3.5.0->spacy_transformers)\n",
      "  Using cached thinc-8.2.5-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->spacy_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.12.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy_transformers) (2.0.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (1.1.1)\n",
      "Using cached spacy-3.7.5-cp310-cp310-win_amd64.whl (12.1 MB)\n",
      "Using cached thinc-8.2.5-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Installing collected packages: thinc, spacy\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.0.17\n",
      "    Uninstalling thinc-8.0.17:\n",
      "      Successfully uninstalled thinc-8.0.17\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.3.3\n",
      "    Uninstalling spacy-3.3.3:\n",
      "      Successfully uninstalled spacy-3.3.3\n",
      "Successfully installed spacy-3.7.5 thinc-8.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "allennlp 2.10.1 requires spacy<3.4,>=2.1.0, but you have spacy 3.7.5 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.23.2)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement random (from versions: none)\n",
      "ERROR: No matching distribution found for random\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: boto3>=1.20.27 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (1.34.101)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.3.5)\n",
      "Requirement already satisfied: conllu>=4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (4.4.2)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (1.2.14)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (6.2.0)\n",
      "Requirement already satisfied: gdown>=4.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (5.2.0)\n",
      "Requirement already satisfied: gensim>=4.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (4.3.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.10.1)\n",
      "Requirement already satisfied: janome>=0.4.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.5.0)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (3.5.3)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (10.2.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (2.8.2)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (2023.12.25)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (1.3.2)\n",
      "Requirement already satisfied: segtok>=1.5.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.9.0)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (1.12.1)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (4.66.2)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.20.1)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (1.26.18)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (0.6.0)\n",
      "Requirement already satisfied: semver<4.0.0,>=3.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flair) (3.0.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.101 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3>=1.20.27->flair) (1.34.101)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3>=1.20.27->flair) (0.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bpemb>=0.3.2->flair) (2.32.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bpemb>=0.3.2->flair) (0.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from deprecated>=1.2.13->flair) (1.14.1)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown>=4.4.0->flair) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown>=4.4.0->flair) (3.7.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim>=4.2.0->flair) (1.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim>=4.2.0->flair) (6.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (21.3)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2.3->flair) (4.35.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2.3->flair) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mpld3>=0.3->flair) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.63.0->flair) (0.4.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.12.1)\n",
      "Collecting protobuf<=3.20.1 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading protobuf-3.20.1-cp310-cp310-win_amd64.whl.metadata (698 bytes)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->mpld3>=0.3->flair) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
      "Downloading protobuf-3.20.1-cp310-cp310-win_amd64.whl (903 kB)\n",
      "   ---------------------------------------- 0.0/903.8 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/903.8 kB 667.8 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 112.6/903.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 245.8/903.8 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 358.4/903.8 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 522.2/903.8 kB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 665.6/903.8 kB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 819.2/903.8 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 903.8/903.8 kB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed protobuf-3.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "allennlp 2.10.1 requires spacy<3.4,>=2.1.0, but you have spacy 3.7.5 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
      "google-api-core 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
      "googleapis-common-protos 1.63.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
      "grpcio-status 1.62.2 requires protobuf>=4.21.6, but you have protobuf 3.20.1 which is incompatible.\n",
      "happytransformer 3.0.0 requires tokenizers<1.0.0,>=0.13.3, but you have tokenizers 0.12.1 which is incompatible.\n",
      "happytransformer 3.0.0 requires transformers<5.0.0,>=4.30.1, but you have transformers 4.20.1 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: python-docx in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------- ----------- 30.7/43.6 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 530.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.9.1)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4) (2.4.1)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.7.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n",
      "Using cached huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.3 MB 2.2 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.1/9.3 MB 1.8 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/9.3 MB 2.1 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/9.3 MB 2.0 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/9.3 MB 1.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.7/9.3 MB 2.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 3.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.7/9.3 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.8/9.3 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.4/9.3 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.8/9.3 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.8/9.3 MB 10.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.0/9.3 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.0/9.3 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.0/9.3 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.0/9.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.8/9.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.2/9.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.2/9.3 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.5/9.3 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.3 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.3 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.3 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 4.9 MB/s eta 0:00:00\n",
      "Using cached tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.20.1\n",
      "    Uninstalling transformers-4.20.1:\n",
      "      Successfully uninstalled transformers-4.20.1\n",
      "Successfully installed huggingface-hub-0.23.4 tokenizers-0.19.1 transformers-4.42.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "allennlp 2.10.1 requires spacy<3.4,>=2.1.0, but you have spacy 3.7.5 which is incompatible.\n",
      "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.42.4 which is incompatible.\n",
      "cached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.23.4 which is incompatible.\n",
      "spacy-transformers 1.3.5 requires transformers<4.37.0,>=3.4.0, but you have transformers 4.42.4 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 653.6 kB/s eta 0:00:20\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "      --------------------------------------- 0.2/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.3/12.8 MB 1.8 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.4/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.8/12.8 MB 2.9 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.3/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/12.8 MB 7.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.2/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.2/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.2/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.2/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.3/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.5/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.5/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.1/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.8/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.1/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.4/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.0/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.8/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.0/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.2/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.6/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.6/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.2)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.42.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.23.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.7.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.5.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Libraries  to be install\n",
    "! pip install pdfplumber python-docx\n",
    "! pip install spacy_transformers\n",
    "! pip install -U spacy\n",
    "! pip install pickle\n",
    "! pip install random\n",
    "! pip install tqdm\n",
    "! pip install nltk\n",
    "! pip install flair\n",
    "# for the jd matching\n",
    "! pip install sentence-transformers numpy beautifulsoup4 pdfplumber python-docx spacy nltk\n",
    "! python -m spacy download en_core_web_sm\n",
    "! pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e591ffa",
   "metadata": {},
   "source": [
    "Line Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2608b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "\n",
    "# Load your specific flair model\n",
    "# For example, \n",
    "# model = flair.models.TextClassifier.load('en-sentiment')\n",
    "\n",
    "# Get the model version\n",
    "\n",
    "\n",
    "print(flair.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d232362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import pdfplumber\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "import random\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm  import tqdm\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBoxHorizontal, LTTextLine, LTChar\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "# import for the jd\n",
    "import numpy as np\n",
    "import docx \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# import pdfplumber\n",
    "# from google.colab import files\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe703875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1880330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51180570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model for the NER\n",
    "nlp=spacy.load('output/model-best')\n",
    "# loading the pos model \n",
    "# pos_tagger = SequenceTagger.load(\"flair/pos-english\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6126b3",
   "metadata": {},
   "source": [
    "Parsing Resume for the Line analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f0a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of the resume:\n"
     ]
    }
   ],
   "source": [
    "# Path for the Resume as the input\n",
    "print(\"Enter the path of the resume:\")\n",
    "file_path = 'Deepank_Singh_cyber.pdf'\n",
    "\n",
    "# # JD Path \n",
    "# print(\"Enter the path of the job description (JD):\")\n",
    "# jd_file = input()\n",
    "\n",
    "# # Skill CSV file\n",
    "# print(\"Enter the path of the skill CSV file:\")\n",
    "# filename = input()\n",
    "\n",
    "# print(\"Press Enter to exit.\")\n",
    "# input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86738141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of each line\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# important line extraction \n",
    "def remove_cid_patterns(line):\n",
    "    return re.sub(r'\\(cid:\\d+\\)', '', line)\n",
    "\n",
    "def merge_consecutive_sentences(lines):\n",
    "    merged_lines = []\n",
    "    current_line = \"\"\n",
    "    bullet_symbols = r'[\\u2022\\u2043\\u25E6\\u2666\\u2735\\u2736\\u2737\\u25CF\\u25AA\\u25AB\\u25A0\\u25A1\\u25B8\\u25D8\\u25E6\\u2713\\u2714\\u2718\\u2719\\u271D\\u2720\\u2721\\u2722\\u2723\\u27A2\\u2794\\u2798\\u27A8\\u27A9\\u25E6\\u25CB]'\n",
    "    for line in lines:\n",
    "        if line.strip()[0].isdigit() or line.strip()[0].isupper() or line.strip().startswith('') or re.search(bullet_symbols, line.strip()):\n",
    "            if current_line:\n",
    "                merged_lines.append(current_line.strip())\n",
    "            current_line = line\n",
    "        else:\n",
    "            current_line += \" \" + line\n",
    "    if current_line:\n",
    "        merged_lines.append(current_line.strip())\n",
    "    return merged_lines\n",
    " \n",
    "def get_synonyms(word):\n",
    "    \n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym = lemma.name().replace('_', ' ')\n",
    "            synonyms.append(synonym)\n",
    "    return synonyms\n",
    "\n",
    "def parse_resume(file_path):\n",
    "    resume_full_text=extract_text_from_pdf(file_path)\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "    # Remove empty lines and (cid:XXX) patterns\n",
    "    text = remove_cid_patterns(text)\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Split sentences into lines using newline character\n",
    "    lines = []\n",
    "    for sentence in sentences:\n",
    "        lines.extend(sentence.split('\\n'))\n",
    "\n",
    "    # Merge consecutive lines\n",
    "    merged_lines = merge_consecutive_sentences(lines)\n",
    "\n",
    "    # Parse the merged lines based on the specified criteria\n",
    "    parsed_lines = []\n",
    "    current_section = None\n",
    "    for line in merged_lines:\n",
    "        line = line.strip()\n",
    "        tokens = word_tokenize(line)\n",
    "\n",
    "        # Check for education section (including synonyms)\n",
    "        education_synonyms = ['education'] + get_synonyms('education')\n",
    "        if any(line.lower().startswith(section.lower()) for section in education_synonyms):\n",
    "            current_section = \"education\"\n",
    "            continue\n",
    "       \n",
    "\n",
    "        # Check for experience section (including synonyms)\n",
    "        experience_synonyms = ['experience'] + get_synonyms('experience')\n",
    "        if any(line.lower().startswith(section.lower()) for section in experience_synonyms):\n",
    "            current_section = \"experience\"\n",
    "            continue\n",
    "        elif current_section == \"experience\" and len(tokens) >= 10:\n",
    "            parsed_lines.append(line)\n",
    "\n",
    "        # Check for project section (including synonyms)\n",
    "        project_synonyms = ['projects'] + get_synonyms('projects')\n",
    "        if any(line.lower().startswith(section.lower()) for section in project_synonyms):\n",
    "            current_section = \"projects\"\n",
    "            continue\n",
    "        elif current_section == \"projects\" and len(tokens) >= 12:\n",
    "            parsed_lines.append(line)\n",
    "\n",
    "        # Check for skills section (including synonyms)\n",
    "        skills_synonyms = ['skills', 'technical skills', 'soft skills'] + get_synonyms('skills')\n",
    "        if any(line.lower().startswith(section.lower()) for section in skills_synonyms):\n",
    "            current_section = \"skills\"\n",
    "            continue\n",
    "\n",
    "        # Check for achievement section (including synonyms)\n",
    "        achievement_synonyms = ['achievements'] + get_synonyms('achievements')\n",
    "        if any(line.lower().startswith(section.lower()) for section in achievement_synonyms):\n",
    "            current_section = \"achievements\"\n",
    "            continue\n",
    "        elif current_section == \"achievements\" and len(tokens) >= 5:\n",
    "            parsed_lines.append(line)\n",
    "\n",
    "\n",
    "    # Filter out lines with less than 5 tokens\n",
    "    final_lines = [line for line in parsed_lines if len(word_tokenize(line)) >= 5]\n",
    "\n",
    "    return resume_full_text,final_lines\n",
    "\n",
    "# Usage\n",
    "# pdf_resume_text contian the  whole text of the resume \n",
    "#parsed lines contain the import lines for the reume \n",
    "pdf_resume_text,parsed_lines = parse_resume(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "644bd8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Engineered a web extension that detects malicious URLs on webpages, achieving a 99% success rate in identifying threats and ensuring user safety.', ' Leveraged advanced deep learning techniques, resulting in a 95% accuracy rate for malicious URL detection, significantly reducing false positives and negatives.', ' Leveraged federated learning techniques to facilitate decentralized data collection and training, enabling a collaborative and privacy-preserving approach to model development.', ' Tech Stack: Tensorflow, PySyft, Javascript,JWT, React-js, Twailwind-CSS ,Node-js', ' Engineered a software application for image steganography utilizing the LSB algorithm, enabling text embedding capacity of up to 25%.', ' Integrated a robust cipher algorithm for text encryption, ensuring 95% security, decreased vulnerability to cyber attacks by 50% and enhanced data protection compliance by 40%.', ' Tech Stack: Python, Cryptography , Stegano Library, PyCryptodome library.', ' Developed a React app utilizing the CoinGecko API to display real-time cryptocurrency price data, including profit/loss , achieving a user satisfaction rate of 92%', ' Employed indicators and a line graph via react-chartjs to furnish visual analytics, thereby bolstering workflow efficiency by 30% through an intuitive interface and fortified user authentication.', ' Achieved finalist position in Rajasthan Police Hackathon 1.0, exhibiting innovative problem-solving capabilities in cyber Security.', ' Secured 10th position in Tri-NIT hackathon, showcasing problem-solving and technical skills.', ' Achieved Rank 2 (Till date) in IT Department students in the CSE.', ' Achieved a top 2% rank in the IIT-JEE Advanced 2021 exam']\n"
     ]
    }
   ],
   "source": [
    "print(parsed_lines)\n",
    "# print(pdf_resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99c0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def process_line(line):\n",
    "#     doc = nlp(line)\n",
    "#     action_verbs = []\n",
    "#     tasks = []\n",
    "#     results = []\n",
    "    \n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == \"Action Verb\":\n",
    "#             action_verbs.append(ent.text)\n",
    "#         elif ent.label_ == \"Task\":\n",
    "#             tasks.append(ent.text)\n",
    "#         elif ent.label_ == \"Result\":\n",
    "#             results.append(ent.text)\n",
    "    \n",
    "#     return len(action_verbs), len(tasks), len(results)\n",
    "\n",
    "# # Usage\n",
    "\n",
    "# # lines = extract_lines_from_pdf(file_path)\n",
    "\n",
    "# line_counts = {}\n",
    "\n",
    "# for i, line in enumerate(parsed_lines, start=1):\n",
    "#     action_verb_count, task_count, result_count = process_line(line)\n",
    "#     line_counts[i] = {\n",
    "#         \"line\": line,\n",
    "#         \"action_verb_count\": action_verb_count,\n",
    "#         \"task_count\": task_count,\n",
    "#         \"result_count\": result_count\n",
    "#     }\n",
    "\n",
    "# # # Print the line counts\n",
    "# for line_number, counts in line_counts.items():\n",
    "#     print(f\"Line {line_number}:\")\n",
    "#     print(f\"  Line: {counts['line']}\")\n",
    "#     print(f\"  Action Verb Count: {counts['action_verb_count']}\")\n",
    "#     print(f\"  Task Count: {counts['task_count']}\")\n",
    "#     print(f\"  Result Count: {counts['result_count']}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a93427",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e7fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "# extraction of the verb and result from the import lines from the resume\n",
    "def remove_cid_patterns(line):\n",
    "    return re.sub(r'\\(cid:\\d+\\)', '', line)\n",
    "\n",
    "def extract_lines_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        lines = []\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            lines.extend(text.split('\\n'))\n",
    "    \n",
    "    # Remove empty lines and (cid:XXX) patterns\n",
    "    lines = [remove_cid_patterns(line) for line in lines if line.strip()]\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def process_line(line):\n",
    "    doc = nlp(line)\n",
    "    action_verbs = []\n",
    "    tasks = []\n",
    "    results = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"Action Verb\":\n",
    "            action_verbs.append(ent.text)\n",
    "        elif ent.label_ == \"Task\":\n",
    "            tasks.append(ent.text)\n",
    "        elif ent.label_ == \"Result\":\n",
    "            results.append(ent.text)\n",
    "    \n",
    "    return action_verbs, tasks, results\n",
    "\n",
    "# Usage\n",
    "\n",
    "\n",
    "\n",
    "line_counts = {}\n",
    "line_results = {}\n",
    "line_action_verbs = {}\n",
    "\n",
    "for i, line in enumerate(parsed_lines, start=1):\n",
    "    action_verbs, tasks, results = process_line(line)\n",
    "    line_counts[i] = {\n",
    "        \"line\": line,\n",
    "        \"action_verb_count\": len(action_verbs),\n",
    "        \"task_count\": len(tasks),\n",
    "        \"result_count\": len(results)\n",
    "    }\n",
    "    line_results[i] = results\n",
    "    line_action_verbs[i] = action_verbs\n",
    "\n",
    "# # Print the line counts\n",
    "# for line_number, counts in line_counts.items():\n",
    "#     print(f\"Line {line_number}:\")\n",
    "#     print(f\"  Line: {counts['line']}\")\n",
    "#     print(f\"  Action Verb Count: {counts['action_verb_count']}\")\n",
    "#     print(f\"  Task Count: {counts['task_count']}\")\n",
    "#     print(f\"  Result Count: {counts['result_count']}\")\n",
    "#     print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ae64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deeebc8d",
   "metadata": {},
   "source": [
    " # Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f9f46",
   "metadata": {},
   "source": [
    "Resume_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd54cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.5 strength matrix \n",
    "\n",
    "def calculate_resume_impact(line_counts):\n",
    "    total_sentences = len(line_counts)\n",
    "    sentences_with_result = sum(1 for counts in line_counts.values() if counts['result_count'] > 0)\n",
    "    \n",
    "    if total_sentences > 0:\n",
    "        print(\"the total number of the line with impact are :\",  sentences_with_result)\n",
    "        impact = (sentences_with_result * 7.5) / total_sentences\n",
    "    else:\n",
    "        impact = 0\n",
    "    \n",
    "    return impact\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad54577",
   "metadata": {},
   "source": [
    "Resume Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed96962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.5 strength matrix\n",
    "\n",
    "def calculate_resume_strength(line_results, line_counts):\n",
    "    total_sentences = len(line_counts)\n",
    "    sentences_with_numeric_result = sum(1 for results in line_results.values() if any(re.search(r'\\d', result) for result in results))\n",
    "    \n",
    "    if total_sentences > 0:\n",
    "        resume_strength = (sentences_with_numeric_result * 12.5) / total_sentences\n",
    "    else:\n",
    "        resume_strength = 0\n",
    "    print(\" Total number of the result with numerical value is : \", sentences_with_numeric_result)\n",
    "    return resume_strength\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3a4fe",
   "metadata": {},
   "source": [
    " Action_Verb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293baa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "def calculate_verb_impact(line_counts):\n",
    "    total_sentences = len(line_counts)\n",
    "    sentences_with_result = sum(1 for counts in line_counts.values() if counts['action_verb_count'] > 0)\n",
    "    \n",
    "    if total_sentences > 0:\n",
    "        print(\"the total number of the line with action verb are :\",  sentences_with_result)\n",
    "        impact = (sentences_with_result * 5) / total_sentences\n",
    "    else:\n",
    "        impact = 0\n",
    "    \n",
    "    return impact\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6da2e",
   "metadata": {},
   "source": [
    "Repetitive Action verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f18ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_repetitive_verbs(line_action_verbs):\n",
    "    total_repetitive_verbs = 0\n",
    "\n",
    "    for line_number, action_verbs in line_action_verbs.items():\n",
    "        verb_counter = Counter(action_verbs)\n",
    "        repetitive_verbs = sum(count - 1 for verb, count in verb_counter.items() if count > 1)\n",
    "        total_repetitive_verbs += repetitive_verbs\n",
    "\n",
    "        if repetitive_verbs > 0:\n",
    "            print(f\"Line {line_number}:\")\n",
    "            for verb, count in verb_counter.items():\n",
    "                if count > 1:\n",
    "                    print(f\"  {verb} (repeated {count} times)\")\n",
    "\n",
    "    return total_repetitive_verbs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d823a",
   "metadata": {},
   "source": [
    " Task Count\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8be47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sentence count and output outof 5\n",
    "def calculate_task_impact(line_counts):\n",
    "    total_sentences = len(line_counts)\n",
    "    sentences_with_result = sum(1 for counts in line_counts.values() if counts['task_count'] > 0)\n",
    "    \n",
    "    if total_sentences > 0:\n",
    "        print(\"the total number of the line with  task  are :\",  sentences_with_result)\n",
    "        impact = (sentences_with_result * 5) / total_sentences\n",
    "    else:\n",
    "        impact = 0\n",
    "    \n",
    "    return impact\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d60383",
   "metadata": {},
   "source": [
    "Language (Not complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25bbaffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_cid_patterns(line):\n",
    "#     return re.sub(r'\\(cid:\\d+\\)', '', line)\n",
    "\n",
    "# def merge_consecutive_sentences(lines):\n",
    "#     merged_lines = []\n",
    "#     current_line = \"\"\n",
    "#     bullet_symbols = r'[\\u2022\\u2043\\u25E6\\u2666\\u2735\\u2736\\u2737\\u25CF\\u25AA\\u25AB\\u25A0\\u25A1\\u25B8\\u25D8\\u25E6\\u2713\\u2714\\u2718\\u2719\\u271D\\u2720\\u2721\\u2722\\u2723\\u27A2\\u2794\\u2798\\u27A8\\u27A9\\u25E6\\u25CB]'\n",
    "#     for line in lines:\n",
    "#         if line.strip()[0].isdigit() or line.strip()[0].isupper() or line.strip().startswith('') or re.search(bullet_symbols, line.strip()):\n",
    "#             if current_line:\n",
    "#                 merged_lines.append(current_line.strip())\n",
    "#             current_line = line\n",
    "#         else:\n",
    "#             current_line += \" \" + line\n",
    "#     if current_line:\n",
    "#         merged_lines.append(current_line.strip())\n",
    "#     return merged_lines\n",
    "\n",
    "# def get_synonyms(word):\n",
    "#     synonyms = []\n",
    "#     for syn in wordnet.synsets(word):\n",
    "#         for lemma in syn.lemmas():\n",
    "#             synonym = lemma.name().replace('_', ' ')\n",
    "#             synonyms.append(synonym)\n",
    "#     return synonyms\n",
    "\n",
    "# def parse_resume(file_path):\n",
    "#     with pdfplumber.open(file_path) as pdf:\n",
    "#         text = ''\n",
    "#         for page in pdf.pages:\n",
    "#             text += page.extract_text()\n",
    "\n",
    "#     # Remove empty lines and (cid:XXX) patterns\n",
    "#     text = remove_cid_patterns(text)\n",
    "\n",
    "#     # Tokenize the text into sentences\n",
    "#     sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "#     # Split sentences into lines using newline character\n",
    "#     lines = []\n",
    "#     for sentence in sentences:\n",
    "#         lines.extend(sentence.split('\\n'))\n",
    "\n",
    "#     # Merge consecutive lines\n",
    "#     merged_lines = merge_consecutive_sentences(lines)\n",
    "\n",
    "#     return merged_lines\n",
    "\n",
    "# # Usage\n",
    "\n",
    "\n",
    "# Resume_lines = parse_resume(file_path)\n",
    "\n",
    "# # Print the total number of lines\n",
    "# print(f\"Total number of lines: {len(Resume_lines)}\")\n",
    "\n",
    "# print(Resume_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa192aca",
   "metadata": {},
   "source": [
    "Verb Tense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a8040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_verb_tense(lines):\n",
    "    verb_tense_count = 0\n",
    "    total_lines = len(lines)\n",
    "    verb_tags = {\"VBN\",\"VERB\", \"VBZ\", \"VB\", \"VBD\", \"VBG\", \"VBP\"}\n",
    "    for line in lines:\n",
    "        doc = nlp(line)\n",
    "        verb_count = 0\n",
    "        for token in doc:\n",
    "            if token.tag_ in verb_tags:\n",
    "                verb_count += 1\n",
    "\n",
    "        if verb_count > 0:\n",
    "            verb_tense_count += 1\n",
    "\n",
    "    verb_tense_score = (verb_tense_count * 2) / total_lines\n",
    "    print(\"Total number of the verb tense present are \", verb_tense_count)\n",
    "    return verb_tense_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fed5f",
   "metadata": {},
   "source": [
    "Usage of personal pronouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a265b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_personal_pronouns(lines):\n",
    "    pronoun_count = 0\n",
    "    total_lines = len(lines)\n",
    "    pro_tags = {\"PRP\",\"PROPN\", \"PRP$\", \"WP\"}\n",
    "    # pos_tag = token.annotation_layers['pos'][0].value\n",
    "    for line in lines:\n",
    "        sentence = Sentence(line)\n",
    "        \n",
    "        doc = nlp(line)\n",
    "        for token in doc:\n",
    "            if token.tag_ in pro_tags:\n",
    "                pronoun_count += 1\n",
    "                break\n",
    "        # for token in sentence:\n",
    "        #     pos_tag = token.annotation_layers['pos'][0].value\n",
    "        #     if pos_tag in pro_tags:\n",
    "        #         print(token.text)\n",
    "        #         pronoun_count += 1\n",
    "        #         break  # Break after finding the first pronoun in the line\n",
    "\n",
    "    pronoun_score = (pronoun_count * 3) / total_lines\n",
    "    print(\"Total number of the verb tense present are \", pronoun_count)\n",
    "    return pronoun_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc381b3",
   "metadata": {},
   "source": [
    "Active Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "796947be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp_voice = spacy.load('en_core_web_sm')\n",
    "\n",
    "def check_voice(sentence):\n",
    "    doc = nlp_voice(sentence)\n",
    "    # Check for active/passive voice\n",
    "    active_voice = sum(1 for token in doc if token.dep_ == 'nsubj' and token.head.pos_ == 'VERB')\n",
    "    passive_voice = sum(1 for token in doc if token.dep_ == 'nsubjpass' and token.head.pos_ == 'VERB')\n",
    "    if active_voice > passive_voice:\n",
    "        return \"Active Voice\"\n",
    "    elif passive_voice > active_voice:\n",
    "        return \"Passive Voice\"\n",
    "    else:\n",
    "        return \"Unable to determine voice\"\n",
    "\n",
    "def calculate_active_voice_percentage(resume_lines):\n",
    "    total_lines = len(resume_lines)\n",
    "    active_voice_lines = 0\n",
    "\n",
    "    for line in resume_lines:\n",
    "        voice = check_voice(line)\n",
    "        if voice == \"Active Voice\":\n",
    "            active_voice_lines += 1\n",
    "\n",
    "    active_voice_percentage = (active_voice_lines * 3) / total_lines \n",
    "    return active_voice_percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc34d9",
   "metadata": {},
   "source": [
    "Basics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45eadf7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8785aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def preprocess_resume(resume_text):\n",
    "    # Tokenize into sentences\n",
    "    sentences = nltk.sent_tokenize(resume_text)\n",
    "    return sentences\n",
    "\n",
    "# Define action verbs and their strength\n",
    "action_verbs_strength = {\n",
    "    'led': 5, 'managed': 5, 'developed': 4, 'created': 4, 'implemented': 4,\n",
    "    'designed': 4, 'analyzed': 3, 'conducted': 3, 'prepared': 3, 'assisted': 2,\n",
    "    'supported': 2, 'participated': 2, 'helped': 1\n",
    "}\n",
    "\n",
    "def extract_action_verbs(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    action_verbs = [word for word in words if word.lower() in action_verbs_strength]\n",
    "    return action_verbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2482606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_sections_with_ner(resume_text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(resume_text)\n",
    "    sections = {\n",
    "        'personal_info': '',\n",
    "        'work_experience': '',\n",
    "        'education': '',\n",
    "        'skills': ''\n",
    "    }\n",
    "    score = 0\n",
    "\n",
    "    # Regular expressions for common section headers\n",
    "    section_patterns = {\n",
    "        'personal_info': r'\\b(personal|contact|info|information)\\b',\n",
    "        'work_experience': r'\\b(work|experience|employment|job|professional)\\b',\n",
    "        'education': r'\\b(education|academic|qualification|degree)\\b',\n",
    "        'skills': r'\\b(skills|abilities|expertise|competencies)\\b'\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "    for sent in doc.sents:\n",
    "        # Check if the sentence starts a new section\n",
    "        for section, pattern in section_patterns.items():\n",
    "            if re.search(pattern, sent.text, re.IGNORECASE):\n",
    "                current_section = section\n",
    "                break\n",
    "        \n",
    "        # Extract information based on the current section or entity recognition\n",
    "        if current_section:\n",
    "            sections[current_section] += sent.text + '\\n'\n",
    "        \n",
    "        # Use NER to extract specific entities\n",
    "        for ent in sent.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                sections['personal_info'] += f\"Name: {ent.text}\\n\"\n",
    "            elif ent.label_ == \"ORG\":\n",
    "                sections['work_experience'] += f\"Organization: {ent.text}\\n\"\n",
    "            elif ent.label_ == \"GPE\":\n",
    "                sections['personal_info'] += f\"Location: {ent.text}\\n\"\n",
    "            elif ent.label_ == \"DATE\":\n",
    "                # Dates could be relevant to multiple sections\n",
    "                if current_section:\n",
    "                    sections[current_section] += f\"Date: {ent.text}\\n\"\n",
    "\n",
    "    # Extract email and phone, and calculate score\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    phone_pattern = r'\\b(?:\\+?(\\d{1,3}))?[-. (]*(\\d{3})[-. )]*(\\d{3})[-. ]*(\\d{4})\\b'\n",
    "\n",
    "    emails = re.findall(email_pattern, resume_text)\n",
    "    phones = re.findall(phone_pattern, resume_text)\n",
    "\n",
    "    if emails:\n",
    "        sections['personal_info'] += f\"Email: {emails[0]}\\n\"\n",
    "        score += 3\n",
    "    if phones:\n",
    "        sections['personal_info'] += f\"Phone: {phones[0]}\\n\"\n",
    "        score += 3\n",
    "\n",
    "    return sections, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "943715b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_resume_with_ner(resume_text):\n",
    "    sections, email_phone_score = extract_sections_with_ner(resume_text)\n",
    "    print(sections)\n",
    "    print(email_phone_score)\n",
    "    score = 0\n",
    "    \n",
    "    # Add score for email and phone number sections\n",
    "    score += email_phone_score\n",
    "    \n",
    "    # Scoring Work Experience\n",
    "    if sections['work_experience']:\n",
    "        score += 4\n",
    "        sentences = preprocess_resume(sections['work_experience'])\n",
    "        for sentence in sentences:\n",
    "            action_verbs = extract_action_verbs(sentence)\n",
    "            for verb in action_verbs:\n",
    "                score += action_verbs_strength[verb.lower()]\n",
    "    \n",
    "    # Scoring Education\n",
    "    if sections['education']:\n",
    "        score += 4\n",
    "    \n",
    "    # Scoring Skills\n",
    "    if sections['skills']:\n",
    "        score += 4\n",
    "    \n",
    "    return score\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c94f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'personal_info': \"Deepank Singh \\nFinal year, Information Technology \\n +91-8168053394  deepanksingh01@gmail.com   LinkedIn    GitHub  \\n \\nEDUCATION________________________________________________________________________________________ \\n \\nRajiv Gandhi Institute of Petroleum Technology (RGIPT), Amethi, Uttar Pradesh                                                 2021-2025 \\n BTech in Information Technology (CPI: 9.12) \\n \\n\\nDate: 2021-2025\\nDAV Public School , Ambala , Haryana                                                                                                                                          2021 \\n \\nName: Ambala\\nName: Haryana\\nIntermediate (Score: 91.02%) \\n\\nName: Ambala\\nName: Haryana\\nLocation: PySyft\\nLocation: Javascript\\nLocation: Node\\nLocation: Metasploit\\nLocation: Nmap\\nName: Burp Suite\\nName: Kali Linux\\nName: Hashcat\\nLocation: Git\\nLocation: Git\\nName: Algorithms\\nName: Engergia\\nLocation: Rajasthan\\nEmail: deepanksingh01@gmail.com\\nPhone: ('91', '816', '805', '3394')\\n\", 'work_experience': 'Organization: Information Technology\\nOrganization: Rajiv Gandhi Institute of Petroleum Technology\\nOrganization: Amethi, Uttar Pradesh\\nOrganization: BTech\\nOrganization: Information Technology\\nOrganization: DAV Public School\\nDAV Public School, Ambala, Haryana                                                                                                                                           2019 \\n Matriculation (Score: 97.60%) \\n \\nWORK EXPERIENCE_______________________________________________________________________________ \\n \\n\\nOrganization: DAV Public School\\nSala- kart  | Remote    (SDE intern)                                                                                                                                 \\nOrganization: Remote    \\nMay2024 \\n \\nPROJECTS___________________________________________________________________________________________ \\n     Web Extension for Malicious URL Detection                                                                                          \\n     (Ongoing) \\n \\nEngineered a web extension that detects malicious URLs on webpages, achieving a 99% success rate in identifying threats and \\nensuring user safety. \\n\\n \\nLeveraged advanced deep learning techniques, resulting in a 95% accuracy rate for malicious URL detection, significantly \\nreducing false positives and negatives. \\n\\n \\nLeveraged federated learning techniques to facilitate decentralized data collection and training, enabling a collaborative and \\nprivacy-preserving approach to model development. \\n\\nOrganization:  \\nLeveraged\\n \\nTech Stack: Tensorflow, PySyft, Javascript,JWT, React-js, Twailwind-CSS ,Node-js \\n \\n     Image steganography                                                                                                                                                                    \\n      \\n \\nEngineered a software application for image steganography utilizing the LSB algorithm, enabling text embedding capacity of up \\nto 25%. \\n\\nOrganization: JWT\\nOrganization: Twailwind-CSS\\nOrganization: LSB\\n \\n\\nIntegrated a robust cipher algorithm for text encryption, ensuring 95% security, decreased vulnerability to cyber attacks by 50% \\nand enhanced data protection compliance by 40%. \\n\\n \\nTech Stack: Python, Cryptography , Stegano Library, PyCryptodome library. \\n \\n      \\nCryto Tracker                                                                                                                                                             \\n       \\n                     \\n \\nDeveloped a React app utilizing the CoinGecko API to display real-time cryptocurrency price data, including profit/loss , \\nachieving a user satisfaction rate of 92% \\n \\nEmployed indicators and a line graph via react-chartjs to furnish visual analytics, thereby bolstering workflow efficiency by 30% \\nthrough an intuitive interface and fortified user authentication. \\n\\n \\n\\nTech Stack: ReactJS,Material UI,Coingecko API \\n \\n \\nSKILLS________________________________________________________________________________________ \\n \\n\\nOrganization: Material UI\\nOrganization: SKILLS\\nProgramming Languages: C++, JavaScript, Python, C,  SQL \\n \\nTools /FrameWorks :  Wireshark, Metasploit, Nmap, Aircrack-ng, Burp Suite ,Kali Linux, Hashcat, OWASP ZAP,React.js, Tailwind CSS, \\nMongoDB,Firebase, Git, Git-hub. \\n \\n\\nOrganization: JavaScript\\nOrganization: SQL\\nOrganization: Wireshark\\nOrganization: React.js, Tailwind CSS\\nOrganization: Firebase\\nCourses : Computer Networking ,Web-Pentesting ,Database Management, Data Structures, Algorithms, Web Technology, Cyber Security. \\n \\n\\nOrganization: Database Management\\nOrganization: Data Structures\\nOrganization: Cyber Security\\nPOSITION OF RESPONSIBILY __________________________________________________________________ \\n \\n \\nOWASP | Technical Head : Responsible for Leading and teaching over 400 student fundamental of Cyber Security. \\n\\nOrganization: RESPONSIBILY\\nOrganization: OWASP\\nOrganization: Cyber Security\\n \\nTechnical Head | Engergia:  Developed the official website for college sport fest ENERGIA. \\n \\n\\nOrganization: ENERGIA\\nACHIEVEMENTS___________________________________________________________________________________ \\n \\nAchieved finalist position in Rajasthan Police Hackathon 1.0, exhibiting innovative problem-solving capabilities in cyber Security. \\n\\nOrganization:  \\nSecured\\nOrganization: Tri-NIT\\nOrganization: IT Department\\nOrganization: CSE\\nOrganization: IIT\\n', 'education': '', 'skills': ' \\nSecured 10th position in Tri-NIT hackathon, showcasing problem-solving and technical skills. \\n\\n \\nAchieved Rank 2 (Till date) in IT Department students in the CSE. \\n\\n \\nAchieved a top 2% rank in the IIT-JEE Advanced 2021 exam \\n\\nDate: 2021\\n'}\n",
      "6\n",
      "Resume Score: 22\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfa1b75b",
   "metadata": {},
   "source": [
    "Style values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5a601b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be writtern  in the final code \n",
    "\n",
    "# Extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "# Check if the document fits within one page\n",
    "def check_page_count(pdf_path):\n",
    "    pdf = PdfReader(pdf_path)\n",
    "    return len(pdf.pages) == 1\n",
    "\n",
    "# Extract fonts and sizes\n",
    "def extract_fonts(pdf_path):\n",
    "    fonts = set()\n",
    "    with open(pdf_path, 'rb') as fp:\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        laparams = LAParams()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.get_pages(fp):\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            for element in layout:\n",
    "                if isinstance(element, (LTTextBoxHorizontal, LTTextLine)):\n",
    "                    for text_line in element:\n",
    "                        if isinstance(text_line, LTTextLine):\n",
    "                            for character in text_line:\n",
    "                                if isinstance(character, LTChar):\n",
    "                                    fonts.add((character.fontname, character.size))\n",
    "    return fonts\n",
    "\n",
    "# Check for required sections\n",
    "def check_sections(text):\n",
    "    sections = [\"Summary\", \"Experience\", \"Education\", \"Skills\", \"Projects\", \"Certifications\", \"Languages\"]\n",
    "    found_sections = {section: re.search(section, text, re.IGNORECASE) is not None for section in sections}\n",
    "    return found_sections\n",
    "\n",
    "# Check bullet point lengths and sequences\n",
    "def check_bullet_points(text):\n",
    "    bullet_points = re.findall(r'\\s*(.*?)\\n', text)\n",
    "    bullet_lengths = [len(bullet) for bullet in bullet_points]\n",
    "    \n",
    "    # Check for three consecutive bullet points\n",
    "    consecutive_bullet_points = False\n",
    "    bullet_sequences = text.split('\\n')\n",
    "    bullet_count = 0\n",
    "    for line in bullet_sequences:\n",
    "        if '' in line:\n",
    "            bullet_count += 1\n",
    "            if bullet_count == 3:\n",
    "                consecutive_bullet_points = True\n",
    "                break\n",
    "        else:\n",
    "            bullet_count = 0\n",
    "    \n",
    "    return bullet_lengths, consecutive_bullet_points\n",
    "\n",
    "# Analyze the resume\n",
    "\n",
    "font_data = extract_fonts(file_path)\n",
    "found_sections = check_sections(pdf_resume_text)\n",
    "bullet_lengths, consecutive_bullet_points = check_bullet_points(pdf_resume_text)\n",
    "fits_in_one_page = check_page_count(file_path)\n",
    "\n",
    "# Determine font consistency\n",
    "font_names = [font[0] for font in font_data]\n",
    "font_sizes = [font[1] for font in font_data]\n",
    "consistent_font_style = len(set(font_names)) == 1\n",
    "consistent_font_size = len(set(font_sizes)) == 1\n",
    "\n",
    "# Determine bullet point length consistency\n",
    "consistent_bullet_lengths = len(set(bullet_lengths)) <= 2  # Allowing some variation\n",
    "\n",
    "# Print results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46bf339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume sroce\n",
      " Total number of the result with numerical value is :  5\n",
      "Resume Strength: 4.81 \n",
      "\n",
      "the total number of the line with impact are : 8\n",
      "Resume Impact: 4.62 \n",
      "\n",
      "the total number of the line with  task  are : 2\n",
      "Task Impact: 0.77 \n",
      "\n",
      "\n",
      "Total Repetitive Verbs: 0 \n",
      "\n",
      "the total number of the line with action verb are : 1\n",
      "Action_verb Impact: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of the verb tense present are  0\n",
      "Verb Tense Score: 0.0 \n",
      " \n",
      "\n",
      "Total number of the verb tense present are  0\n",
      "Pronoun Score: 0.0\n",
      "\n",
      "Percentage of lines in active voice: 0.92\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "Font Data:\n",
      "Font: BCDIEE+Roboto, Size: 9.960000000000036\n",
      "Font: BCDKEE+Calibri-Italic, Size: 9.960000000000036\n",
      "Font: BCDNEE+Calibri-Bold, Size: 9.960000000000036\n",
      "Font: BCDGEE+Roboto,Bold, Size: 11.039999999999992\n",
      "Font: BCDJEE+Roboto,Italic, Size: 9.960000000000036\n",
      "Font: ArialMT, Size: 6.960000000000008\n",
      "Font: BCDHEE+Calibri-Italic, Size: 9.0\n",
      "Font: BCDEEE+Calibri, Size: 9.960000000000008\n",
      "Font: BCDNEE+Calibri-Bold, Size: 9.960000000000008\n",
      "Font: TimesNewRomanPSMT, Size: 9.959999999999923\n",
      "Font: ArialMT, Size: 9.0\n",
      "Font: TimesNewRomanPSMT, Size: 9.959999999999994\n",
      "Font: BCDEEE+Calibri, Size: 9.0\n",
      "Font: SymbolMT, Size: 9.0\n",
      "Font: BCDGEE+Roboto,Bold, Size: 11.039999999999964\n",
      "Font: BCDEEE+Calibri, Size: 12.0\n",
      "Font: BCDGEE+Roboto,Bold, Size: 9.960000000000036\n",
      "Font: BCDNEE+Calibri-Bold, Size: 9.0\n",
      "Font: TimesNewRomanPS-BoldMT, Size: 12.0\n",
      "Font: TimesNewRomanPSMT, Size: 11.039999999999964\n",
      "Font: BCDJEE+Roboto,Italic, Size: 9.0\n",
      "Font: TimesNewRomanPS-BoldMT, Size: 9.0\n",
      "Font: TimesNewRomanPS-BoldMT, Size: 24.0\n",
      "Font: TimesNewRomanPSMT, Size: 9.960000000000036\n",
      "Font: BCDGEE+Roboto,Bold, Size: 9.960000000000008\n",
      "Font: BCDMEE+Calibri, Size: 9.960000000000036\n",
      "Font: TimesNewRomanPSMT, Size: 9.960000000000008\n",
      "Font: BCDMEE+Calibri, Size: 6.960000000000008\n",
      "Font: TimesNewRomanPSMT, Size: 9.0\n",
      "Font: TimesNewRomanPSMT, Size: 12.0\n",
      "Font: BCDNEE+Calibri-Bold, Size: 11.039999999999992\n",
      "Font: BCDHEE+Calibri-Italic, Size: 9.960000000000036\n",
      "Font: BCDLEE+Roboto Thin, Size: 9.960000000000036\n",
      "Font: BCDMEE+Calibri, Size: 9.0\n",
      "Font: ArialMT, Size: 9.960000000000036\n",
      "Font: BCDEEE+Calibri, Size: 9.960000000000036\n",
      "\n",
      "Consistent Font Style: No\n",
      "Consistent Font Size: No\n",
      "\n",
      "Bullet Points Lengths:\n",
      "Bullet 1: 66 characters\n",
      "Bullet 2: 124 characters\n",
      "Bullet 3: 121 characters\n",
      "Bullet 4: 127 characters\n",
      "Bullet 5: 81 characters\n",
      "Bullet 6: 126 characters\n",
      "Bullet 7: 129 characters\n",
      "Bullet 8: 74 characters\n",
      "Bullet 9: 122 characters\n",
      "Bullet 10: 130 characters\n",
      "Bullet 11: 46 characters\n",
      "Bullet 12: 132 characters\n",
      "Bullet 13: 93 characters\n",
      "Bullet 14: 66 characters\n",
      "Bullet 15: 57 characters\n",
      "\n",
      "Consistent Bullet Point Lengths: No\n",
      "Three Consecutive Bullet Points: No\n",
      "\n",
      "Required Sections Found:\n",
      "Summary: Not Found\n",
      "Experience: Found\n",
      "Education: Found\n",
      "Skills: Found\n",
      "Projects: Found\n",
      "Certifications: Not Found\n",
      "Languages: Found\n",
      "\n",
      "Fits in One Page: Yes\n",
      "/n /n\n",
      "{'personal_info': \"Deepank Singh \\nFinal year, Information Technology \\n +91-8168053394  deepanksingh01@gmail.com   LinkedIn    GitHub  \\n \\nEDUCATION________________________________________________________________________________________ \\n \\nRajiv Gandhi Institute of Petroleum Technology (RGIPT), Amethi, Uttar Pradesh                                                 2021-2025 \\n BTech in Information Technology (CPI: 9.12) \\n \\n\\nDate: 2021-2025\\nDAV Public School , Ambala , Haryana                                                                                                                                          2021 \\n \\nName: Ambala\\nName: Haryana\\nIntermediate (Score: 91.02%) \\n\\nName: Ambala\\nName: Haryana\\nLocation: PySyft\\nLocation: Javascript\\nLocation: Node\\nLocation: Metasploit\\nLocation: Nmap\\nName: Burp Suite\\nName: Kali Linux\\nName: Hashcat\\nLocation: Git\\nLocation: Git\\nName: Algorithms\\nName: Engergia\\nLocation: Rajasthan\\nEmail: deepanksingh01@gmail.com\\nPhone: ('91', '816', '805', '3394')\\n\", 'work_experience': 'Organization: Information Technology\\nOrganization: Rajiv Gandhi Institute of Petroleum Technology\\nOrganization: Amethi, Uttar Pradesh\\nOrganization: BTech\\nOrganization: Information Technology\\nOrganization: DAV Public School\\nDAV Public School, Ambala, Haryana                                                                                                                                           2019 \\n Matriculation (Score: 97.60%) \\n \\nWORK EXPERIENCE_______________________________________________________________________________ \\n \\n\\nOrganization: DAV Public School\\nSala- kart  | Remote    (SDE intern)                                                                                                                                 \\nOrganization: Remote    \\nMay2024 \\n \\nPROJECTS___________________________________________________________________________________________ \\n     Web Extension for Malicious URL Detection                                                                                          \\n     (Ongoing) \\n \\nEngineered a web extension that detects malicious URLs on webpages, achieving a 99% success rate in identifying threats and \\nensuring user safety. \\n\\n \\nLeveraged advanced deep learning techniques, resulting in a 95% accuracy rate for malicious URL detection, significantly \\nreducing false positives and negatives. \\n\\n \\nLeveraged federated learning techniques to facilitate decentralized data collection and training, enabling a collaborative and \\nprivacy-preserving approach to model development. \\n\\nOrganization:  \\nLeveraged\\n \\nTech Stack: Tensorflow, PySyft, Javascript,JWT, React-js, Twailwind-CSS ,Node-js \\n \\n     Image steganography                                                                                                                                                                    \\n      \\n \\nEngineered a software application for image steganography utilizing the LSB algorithm, enabling text embedding capacity of up \\nto 25%. \\n\\nOrganization: JWT\\nOrganization: Twailwind-CSS\\nOrganization: LSB\\n \\n\\nIntegrated a robust cipher algorithm for text encryption, ensuring 95% security, decreased vulnerability to cyber attacks by 50% \\nand enhanced data protection compliance by 40%. \\n\\n \\nTech Stack: Python, Cryptography , Stegano Library, PyCryptodome library. \\n \\n      \\nCryto Tracker                                                                                                                                                             \\n       \\n                     \\n \\nDeveloped a React app utilizing the CoinGecko API to display real-time cryptocurrency price data, including profit/loss , \\nachieving a user satisfaction rate of 92% \\n \\nEmployed indicators and a line graph via react-chartjs to furnish visual analytics, thereby bolstering workflow efficiency by 30% \\nthrough an intuitive interface and fortified user authentication. \\n\\n \\n\\nTech Stack: ReactJS,Material UI,Coingecko API \\n \\n \\nSKILLS________________________________________________________________________________________ \\n \\n\\nOrganization: Material UI\\nOrganization: SKILLS\\nProgramming Languages: C++, JavaScript, Python, C,  SQL \\n \\nTools /FrameWorks :  Wireshark, Metasploit, Nmap, Aircrack-ng, Burp Suite ,Kali Linux, Hashcat, OWASP ZAP,React.js, Tailwind CSS, \\nMongoDB,Firebase, Git, Git-hub. \\n \\n\\nOrganization: JavaScript\\nOrganization: SQL\\nOrganization: Wireshark\\nOrganization: React.js, Tailwind CSS\\nOrganization: Firebase\\nCourses : Computer Networking ,Web-Pentesting ,Database Management, Data Structures, Algorithms, Web Technology, Cyber Security. \\n \\n\\nOrganization: Database Management\\nOrganization: Data Structures\\nOrganization: Cyber Security\\nPOSITION OF RESPONSIBILY __________________________________________________________________ \\n \\n \\nOWASP | Technical Head : Responsible for Leading and teaching over 400 student fundamental of Cyber Security. \\n\\nOrganization: RESPONSIBILY\\nOrganization: OWASP\\nOrganization: Cyber Security\\n \\nTechnical Head | Engergia:  Developed the official website for college sport fest ENERGIA. \\n \\n\\nOrganization: ENERGIA\\nACHIEVEMENTS___________________________________________________________________________________ \\n \\nAchieved finalist position in Rajasthan Police Hackathon 1.0, exhibiting innovative problem-solving capabilities in cyber Security. \\n\\nOrganization:  \\nSecured\\nOrganization: Tri-NIT\\nOrganization: IT Department\\nOrganization: CSE\\nOrganization: IIT\\n', 'education': '', 'skills': ' \\nSecured 10th position in Tri-NIT hackathon, showcasing problem-solving and technical skills. \\n\\n \\nAchieved Rank 2 (Till date) in IT Department students in the CSE. \\n\\n \\nAchieved a top 2% rank in the IIT-JEE Advanced 2021 exam \\n\\nDate: 2021\\n'}\n",
      "6\n",
      "Resume Score: 22\n"
     ]
    }
   ],
   "source": [
    "# The resume scores\n",
    "print(\"Resume sroce\")\n",
    "# Usage\n",
    "#   calculation Resume Strength\n",
    "resume_strength = calculate_resume_strength(line_results, line_counts)\n",
    "print(f\"Resume Strength: {resume_strength:.2f} \\n\")\n",
    "\n",
    "# calculation for the resume impact \n",
    "resume_impact = calculate_resume_impact(line_counts)\n",
    "print(f\"Resume Impact: {resume_impact:.2f} \\n\")\n",
    "\n",
    "resume_task = calculate_task_impact(line_counts)\n",
    "print(f\"Task Impact: {resume_task:.2f} \\n\")\n",
    "\n",
    "# calculation of the repetive action verb\n",
    "total_repetitive_verbs = count_repetitive_verbs(line_action_verbs)\n",
    "print(f\"\\nTotal Repetitive Verbs: {total_repetitive_verbs} \\n\")\n",
    "\n",
    "# For action verb score\n",
    "resume_action_verb = calculate_verb_impact(line_counts)\n",
    "print(f\"Action_verb Impact: {resume_action_verb:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # verb_tense_sroce\n",
    "verb_tense_score = count_verb_tense(parsed_lines )\n",
    "print(f\"Verb Tense Score: {verb_tense_score} \\n \\n\")\n",
    "\n",
    "# personla_pronouns\n",
    "pronoun_score = count_personal_pronouns(parsed_lines )\n",
    "print(f\"Pronoun Score: {pronoun_score}\\n\")\n",
    "\n",
    "# ative voice score\n",
    "active_voice_percentage = calculate_active_voice_percentage(parsed_lines )   # for all resume Lines the replace the parsed_lines from the Resume_lines\n",
    "print(f\"Percentage of lines in active voice: {active_voice_percentage:.2f}\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n \\n \\n\")\n",
    "# for the sylte\n",
    "print(\"Font Data:\")\n",
    "for font in font_data:\n",
    "    print(f\"Font: {font[0]}, Size: {font[1]}\")\n",
    "\n",
    "print(f\"\\nConsistent Font Style: {'Yes' if consistent_font_style else 'No'}\")\n",
    "print(f\"Consistent Font Size: {'Yes' if consistent_font_size else 'No'}\")\n",
    "\n",
    "print(\"\\nBullet Points Lengths:\")\n",
    "for i, length in enumerate(bullet_lengths, 1):\n",
    "    print(f\"Bullet {i}: {length} characters\")\n",
    "\n",
    "print(f\"\\nConsistent Bullet Point Lengths: {'Yes' if consistent_bullet_lengths else 'No'}\")\n",
    "print(f\"Three Consecutive Bullet Points: {'Yes' if consecutive_bullet_points else 'No'}\")\n",
    "\n",
    "print(\"\\nRequired Sections Found:\")\n",
    "for section, found in found_sections.items():\n",
    "    status = \"Found\" if found else \"Not Found\"\n",
    "    print(f\"{section}: {status}\")\n",
    "\n",
    "print(f\"\\nFits in One Page: {'Yes' if fits_in_one_page else 'No'}\")\n",
    "\n",
    "print(\"/n /n\")\n",
    "\n",
    "score = score_resume_with_ner(pdf_resume_text)\n",
    "print(f\"Resume Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93961ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d40afcc",
   "metadata": {},
   "source": [
    "# Jd and Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922564d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b98c58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load spaCy model for sentence segmentation\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to upload files in Google Colab\n",
    "\n",
    "\n",
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text=\"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract text from DOCX files\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = ''\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + '\\n'\n",
    "    return text\n",
    "\n",
    "# Function to extract text from TXT files\n",
    "def extract_text_from_txt(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (clean HTML tags, etc.)\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Regex Cleaning\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s'-.]\", '', text)\n",
    "    # Clean html tags.\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    clean_text = soup.get_text()\n",
    "    clean_text = clean_text.replace('\\n', ' ').replace('\\r', '')\n",
    "    return clean_text\n",
    "\n",
    "# Function to extract text based on file extension\n",
    "def extract_text(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        return extract_text_from_txt(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "# Function to split text into sentences using spaCy\n",
    "def split_into_sentences_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc4decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For the resume\n",
    "resume_text = preprocess_text(pdf_resume_text)\n",
    "resume_sentences = split_into_sentences_spacy(resume_text)\n",
    "\n",
    "# For the job description\n",
    "jd_text = preprocess_text(extract_text_from_pdf(jd_file))\n",
    "job_description_sentences = split_into_sentences_spacy(jd_text)\n",
    "\n",
    "# If you need the flattened lists (which isn't necessary in this case as you have only one resume and one JD)\n",
    "flat_resume_sentences = resume_sentences\n",
    "flat_job_description_sentences = job_description_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "711daf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepank singh  final year, information technology   +91-8168053394  deepanksingh01gmail.com   linkedin    github     education    rajiv gandhi institute of petroleum technology (rgipt), amethi, uttar pradesh                                                 2021-2025   btech in information technology (cpi 9.12)    dav public school , ambala , haryana                                                                                                                                          2021   intermediate (score 91.02)  dav public school, ambala, haryana                                                                                                                                           2019   matriculation (score 97.60)    work experience    sala- kart   remote    (sde intern)                                                                                                                                 may2024    projects       web extension for malicious url detection                                                                                                (ongoing)    engineered a web extension that detects malicious urls on webpages, achieving a 99 success rate in identifying threats and  ensuring user safety.    leveraged advanced deep learning techniques, resulting in a 95 accuracy rate for malicious url detection, significantly  reducing false positives and negatives.    leveraged federated learning techniques to facilitate decentralized data collection and training, enabling a collaborative and  privacy-preserving approach to model development.    tech stack tensorflow, pysyft, javascript,jwt, react-js, twailwind-css ,node-js         image steganography                                                                                                                                                                              engineered a software application for image steganography utilizing the lsb algorithm, enabling text embedding capacity of up  to 25.    integrated a robust cipher algorithm for text encryption, ensuring 95 security, decreased vulnerability to cyber attacks by 50  and enhanced data protection compliance by 40.    tech stack python, cryptography , stegano library, pycryptodome library.          cryto tracker                                                                                                                                                                                              developed a react app utilizing the coingecko api to display real-time cryptocurrency price data, including profitloss ,  achieving a user satisfaction rate of 92    employed indicators and a line graph via react-chartjs to furnish visual analytics, thereby bolstering workflow efficiency by 30  through an intuitive interface and fortified user authentication.    tech stack reactjs,material ui,coingecko api      skills    programming languages c++, javascript, python, c,  sql    tools frameworks   wireshark, metasploit, nmap, aircrack-ng, burp suite ,kali linux, hashcat, owasp zap,react.js, tailwind css,  mongodb,firebase, git, git-hub.    courses  computer networking ,web-pentesting ,database management, data structures, algorithms, web technology, cyber security.    position of responsibily       owasp  technical head  responsible for leading and teaching over 400 student fundamental of cyber security.    technical head  engergia  developed the official website for college sport fest energia.    achievements    achieved finalist position in rajasthan police hackathon 1.0, exhibiting innovative problem-solving capabilities in cyber security.    secured 10th position in tri-nit hackathon, showcasing problem-solving and technical skills.    achieved rank 2 (till date) in it department students in the cse.    achieved a top 2 rank in the iit-jee advanced 2021 exam  \n",
      "deepank singh final year, information technology  +91-8168053394  deepanksingh01gmail.com  linkedin  github education rajiv gandhi institute of petroleum technology (rgipt), amethi, uttar pradesh 2021-2025 btech in information technology (cpi 9.12) dav public school , ambala , haryana 2021 intermediate (score 91.02) dav public school, ambala, haryana 2019 matriculation (score 97.60) work experience sala- kart  remote (sde intern) may2024 projects web extension for malicious url detection (ongoing)  engineered a web extension that detects malicious urls on webpages, achieving a 99 success rate in identifying threats and ensuring user safety.  leveraged advanced deep learning techniques, resulting in a 95 accuracy rate for malicious url detection, significantly reducing false positives and negatives.  leveraged federated learning techniques to facilitate decentralized data collection and training, enabling a collaborative and privacy-preserving approach to model development.  tech stack tensorflow, pysyft, javascript,jwt, react-js, twailwind-css ,node-js image steganography  engineered a software application for image steganography utilizing the lsb algorithm, enabling text embedding capacity of up to 25.  integrated a robust cipher algorithm for text encryption, ensuring 95 security, decreased vulnerability to cyber attacks by 50 and enhanced data protection compliance by 40.  tech stack python, cryptography , stegano library, pycryptodome library. cryto tracker  developed a react app utilizing the coingecko api to display real-time cryptocurrency price data, including profitloss , achieving a user satisfaction rate of 92  employed indicators and a line graph via react-chartjs to furnish visual analytics, thereby bolstering workflow efficiency by 30 through an intuitive interface and fortified user authentication.  tech stack reactjs,material ui,coingecko api skills programming languages c++, javascript, python, c, sql tools frameworks  wireshark, metasploit, nmap, aircrack-ng, burp suite ,kali linux, hashcat, owasp zap,react.js, tailwind css, mongodb,firebase, git, git-hub. courses  computer networking ,web-pentesting ,database management, data structures, algorithms, web technology, cyber security. position of responsibily   owasp  technical head  responsible for leading and teaching over 400 student fundamental of cyber security.  technical head  engergia developed the official website for college sport fest energia. achievements  achieved finalist position in rajasthan police hackathon 1.0, exhibiting innovative problem-solving capabilities in cyber security.  secured 10th position in tri-nit hackathon, showcasing problem-solving and technical skills.  achieved rank 2 (till date) in it department students in the cse.  achieved a top 2 rank in the iit-jee advanced 2021 exam \n",
      "\n",
      "\n",
      "[['d'], ['e'], ['e'], ['p'], ['a'], ['n'], ['k'], [' '], ['s'], ['i'], ['n'], ['g'], ['h'], [' '], [' '], ['f'], ['i'], ['n'], ['a'], ['l'], [' '], ['y'], ['e'], ['a'], ['r'], [','], [' '], ['i'], ['n'], ['f'], ['o'], ['r'], ['m'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [' '], [' '], [' '], ['+'], ['9'], ['1'], ['-'], ['8'], ['1'], ['6'], ['8'], ['0'], ['5'], ['3'], ['3'], ['9'], ['4'], [' '], [' '], ['d'], ['e'], ['e'], ['p'], ['a'], ['n'], ['k'], ['s'], ['i'], ['n'], ['g'], ['h'], ['0'], ['1'], ['g'], ['m'], ['a'], ['i'], ['l'], ['.'], ['c'], ['o'], ['m'], [' '], [' '], [' '], ['l'], ['i'], ['n'], ['k'], ['e'], ['d'], ['i'], ['n'], [' '], [' '], [' '], [' '], ['g'], ['i'], ['t'], ['h'], ['u'], ['b'], [' '], [' '], [' '], [' '], [' '], ['e'], ['d'], ['u'], ['c'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], [' '], [' '], [' '], ['r'], ['a'], ['j'], ['i'], ['v'], [' '], ['g'], ['a'], ['n'], ['d'], ['h'], ['i'], [' '], ['i'], ['n'], ['s'], ['t'], ['i'], ['t'], ['u'], ['t'], ['e'], [' '], ['o'], ['f'], [' '], ['p'], ['e'], ['t'], ['r'], ['o'], ['l'], ['e'], ['u'], ['m'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [' '], ['('], ['r'], ['g'], ['i'], ['p'], ['t'], [')'], [','], [' '], ['a'], ['m'], ['e'], ['t'], ['h'], ['i'], [','], [' '], ['u'], ['t'], ['t'], ['a'], ['r'], [' '], ['p'], ['r'], ['a'], ['d'], ['e'], ['s'], ['h'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['2'], ['0'], ['2'], ['1'], ['-'], ['2'], ['0'], ['2'], ['5'], [' '], [' '], [' '], ['b'], ['t'], ['e'], ['c'], ['h'], [' '], ['i'], ['n'], [' '], ['i'], ['n'], ['f'], ['o'], ['r'], ['m'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [' '], ['('], ['c'], ['p'], ['i'], [' '], ['9'], ['.'], ['1'], ['2'], [')'], [' '], [' '], [' '], [' '], ['d'], ['a'], ['v'], [' '], ['p'], ['u'], ['b'], ['l'], ['i'], ['c'], [' '], ['s'], ['c'], ['h'], ['o'], ['o'], ['l'], [' '], [','], [' '], ['a'], ['m'], ['b'], ['a'], ['l'], ['a'], [' '], [','], [' '], ['h'], ['a'], ['r'], ['y'], ['a'], ['n'], ['a'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['2'], ['0'], ['2'], ['1'], [' '], [' '], [' '], ['i'], ['n'], ['t'], ['e'], ['r'], ['m'], ['e'], ['d'], ['i'], ['a'], ['t'], ['e'], [' '], ['('], ['s'], ['c'], ['o'], ['r'], ['e'], [' '], ['9'], ['1'], ['.'], ['0'], ['2'], [')'], [' '], [' '], ['d'], ['a'], ['v'], [' '], ['p'], ['u'], ['b'], ['l'], ['i'], ['c'], [' '], ['s'], ['c'], ['h'], ['o'], ['o'], ['l'], [','], [' '], ['a'], ['m'], ['b'], ['a'], ['l'], ['a'], [','], [' '], ['h'], ['a'], ['r'], ['y'], ['a'], ['n'], ['a'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['2'], ['0'], ['1'], ['9'], [' '], [' '], [' '], ['m'], ['a'], ['t'], ['r'], ['i'], ['c'], ['u'], ['l'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['('], ['s'], ['c'], ['o'], ['r'], ['e'], [' '], ['9'], ['7'], ['.'], ['6'], ['0'], [')'], [' '], [' '], [' '], [' '], ['w'], ['o'], ['r'], ['k'], [' '], ['e'], ['x'], ['p'], ['e'], ['r'], ['i'], ['e'], ['n'], ['c'], ['e'], [' '], [' '], [' '], [' '], ['s'], ['a'], ['l'], ['a'], ['-'], [' '], ['k'], ['a'], ['r'], ['t'], [' '], [' '], [' '], ['r'], ['e'], ['m'], ['o'], ['t'], ['e'], [' '], [' '], [' '], [' '], ['('], ['s'], ['d'], ['e'], [' '], ['i'], ['n'], ['t'], ['e'], ['r'], ['n'], [')'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['m'], ['a'], ['y'], ['2'], ['0'], ['2'], ['4'], [' '], [' '], [' '], [' '], ['p'], ['r'], ['o'], ['j'], ['e'], ['c'], ['t'], ['s'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['w'], ['e'], ['b'], [' '], ['e'], ['x'], ['t'], ['e'], ['n'], ['s'], ['i'], ['o'], ['n'], [' '], ['f'], ['o'], ['r'], [' '], ['m'], ['a'], ['l'], ['i'], ['c'], ['i'], ['o'], ['u'], ['s'], [' '], ['u'], ['r'], ['l'], [' '], ['d'], ['e'], ['t'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['('], ['o'], ['n'], ['g'], ['o'], ['i'], ['n'], ['g'], [')'], [' '], [' '], [' '], [' '], ['e'], ['n'], ['g'], ['i'], ['n'], ['e'], ['e'], ['r'], ['e'], ['d'], [' '], ['a'], [' '], ['w'], ['e'], ['b'], [' '], ['e'], ['x'], ['t'], ['e'], ['n'], ['s'], ['i'], ['o'], ['n'], [' '], ['t'], ['h'], ['a'], ['t'], [' '], ['d'], ['e'], ['t'], ['e'], ['c'], ['t'], ['s'], [' '], ['m'], ['a'], ['l'], ['i'], ['c'], ['i'], ['o'], ['u'], ['s'], [' '], ['u'], ['r'], ['l'], ['s'], [' '], ['o'], ['n'], [' '], ['w'], ['e'], ['b'], ['p'], ['a'], ['g'], ['e'], ['s'], [','], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], [' '], ['9'], ['9'], [' '], ['s'], ['u'], ['c'], ['c'], ['e'], ['s'], ['s'], [' '], ['r'], ['a'], ['t'], ['e'], [' '], ['i'], ['n'], [' '], ['i'], ['d'], ['e'], ['n'], ['t'], ['i'], ['f'], ['y'], ['i'], ['n'], ['g'], [' '], ['t'], ['h'], ['r'], ['e'], ['a'], ['t'], ['s'], [' '], ['a'], ['n'], ['d'], [' '], [' '], ['e'], ['n'], ['s'], ['u'], ['r'], ['i'], ['n'], ['g'], [' '], ['u'], ['s'], ['e'], ['r'], [' '], ['s'], ['a'], ['f'], ['e'], ['t'], ['y'], ['.'], [' '], [' '], [' '], [' '], ['l'], ['e'], ['v'], ['e'], ['r'], ['a'], ['g'], ['e'], ['d'], [' '], ['a'], ['d'], ['v'], ['a'], ['n'], ['c'], ['e'], ['d'], [' '], ['d'], ['e'], ['e'], ['p'], [' '], ['l'], ['e'], ['a'], ['r'], ['n'], ['i'], ['n'], ['g'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['q'], ['u'], ['e'], ['s'], [','], [' '], ['r'], ['e'], ['s'], ['u'], ['l'], ['t'], ['i'], ['n'], ['g'], [' '], ['i'], ['n'], [' '], ['a'], [' '], ['9'], ['5'], [' '], ['a'], ['c'], ['c'], ['u'], ['r'], ['a'], ['c'], ['y'], [' '], ['r'], ['a'], ['t'], ['e'], [' '], ['f'], ['o'], ['r'], [' '], ['m'], ['a'], ['l'], ['i'], ['c'], ['i'], ['o'], ['u'], ['s'], [' '], ['u'], ['r'], ['l'], [' '], ['d'], ['e'], ['t'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [','], [' '], ['s'], ['i'], ['g'], ['n'], ['i'], ['f'], ['i'], ['c'], ['a'], ['n'], ['t'], ['l'], ['y'], [' '], [' '], ['r'], ['e'], ['d'], ['u'], ['c'], ['i'], ['n'], ['g'], [' '], ['f'], ['a'], ['l'], ['s'], ['e'], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['v'], ['e'], ['s'], [' '], ['a'], ['n'], ['d'], [' '], ['n'], ['e'], ['g'], ['a'], ['t'], ['i'], ['v'], ['e'], ['s'], ['.'], [' '], [' '], [' '], [' '], ['l'], ['e'], ['v'], ['e'], ['r'], ['a'], ['g'], ['e'], ['d'], [' '], ['f'], ['e'], ['d'], ['e'], ['r'], ['a'], ['t'], ['e'], ['d'], [' '], ['l'], ['e'], ['a'], ['r'], ['n'], ['i'], ['n'], ['g'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['q'], ['u'], ['e'], ['s'], [' '], ['t'], ['o'], [' '], ['f'], ['a'], ['c'], ['i'], ['l'], ['i'], ['t'], ['a'], ['t'], ['e'], [' '], ['d'], ['e'], ['c'], ['e'], ['n'], ['t'], ['r'], ['a'], ['l'], ['i'], ['z'], ['e'], ['d'], [' '], ['d'], ['a'], ['t'], ['a'], [' '], ['c'], ['o'], ['l'], ['l'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], ['a'], ['n'], ['d'], [' '], ['t'], ['r'], ['a'], ['i'], ['n'], ['i'], ['n'], ['g'], [','], [' '], ['e'], ['n'], ['a'], ['b'], ['l'], ['i'], ['n'], ['g'], [' '], ['a'], [' '], ['c'], ['o'], ['l'], ['l'], ['a'], ['b'], ['o'], ['r'], ['a'], ['t'], ['i'], ['v'], ['e'], [' '], ['a'], ['n'], ['d'], [' '], [' '], ['p'], ['r'], ['i'], ['v'], ['a'], ['c'], ['y'], ['-'], ['p'], ['r'], ['e'], ['s'], ['e'], ['r'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], ['p'], ['p'], ['r'], ['o'], ['a'], ['c'], ['h'], [' '], ['t'], ['o'], [' '], ['m'], ['o'], ['d'], ['e'], ['l'], [' '], ['d'], ['e'], ['v'], ['e'], ['l'], ['o'], ['p'], ['m'], ['e'], ['n'], ['t'], ['.'], [' '], [' '], [' '], [' '], ['t'], ['e'], ['c'], ['h'], [' '], ['s'], ['t'], ['a'], ['c'], ['k'], [' '], ['t'], ['e'], ['n'], ['s'], ['o'], ['r'], ['f'], ['l'], ['o'], ['w'], [','], [' '], ['p'], ['y'], ['s'], ['y'], ['f'], ['t'], [','], [' '], ['j'], ['a'], ['v'], ['a'], ['s'], ['c'], ['r'], ['i'], ['p'], ['t'], [','], ['j'], ['w'], ['t'], [','], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], ['-'], ['j'], ['s'], [','], [' '], ['t'], ['w'], ['a'], ['i'], ['l'], ['w'], ['i'], ['n'], ['d'], ['-'], ['c'], ['s'], ['s'], [' '], [','], ['n'], ['o'], ['d'], ['e'], ['-'], ['j'], ['s'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['i'], ['m'], ['a'], ['g'], ['e'], [' '], ['s'], ['t'], ['e'], ['g'], ['a'], ['n'], ['o'], ['g'], ['r'], ['a'], ['p'], ['h'], ['y'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['e'], ['n'], ['g'], ['i'], ['n'], ['e'], ['e'], ['r'], ['e'], ['d'], [' '], ['a'], [' '], ['s'], ['o'], ['f'], ['t'], ['w'], ['a'], ['r'], ['e'], [' '], ['a'], ['p'], ['p'], ['l'], ['i'], ['c'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['f'], ['o'], ['r'], [' '], ['i'], ['m'], ['a'], ['g'], ['e'], [' '], ['s'], ['t'], ['e'], ['g'], ['a'], ['n'], ['o'], ['g'], ['r'], ['a'], ['p'], ['h'], ['y'], [' '], ['u'], ['t'], ['i'], ['l'], ['i'], ['z'], ['i'], ['n'], ['g'], [' '], ['t'], ['h'], ['e'], [' '], ['l'], ['s'], ['b'], [' '], ['a'], ['l'], ['g'], ['o'], ['r'], ['i'], ['t'], ['h'], ['m'], [','], [' '], ['e'], ['n'], ['a'], ['b'], ['l'], ['i'], ['n'], ['g'], [' '], ['t'], ['e'], ['x'], ['t'], [' '], ['e'], ['m'], ['b'], ['e'], ['d'], ['d'], ['i'], ['n'], ['g'], [' '], ['c'], ['a'], ['p'], ['a'], ['c'], ['i'], ['t'], ['y'], [' '], ['o'], ['f'], [' '], ['u'], ['p'], [' '], [' '], ['t'], ['o'], [' '], ['2'], ['5'], ['.'], [' '], [' '], [' '], [' '], ['i'], ['n'], ['t'], ['e'], ['g'], ['r'], ['a'], ['t'], ['e'], ['d'], [' '], ['a'], [' '], ['r'], ['o'], ['b'], ['u'], ['s'], ['t'], [' '], ['c'], ['i'], ['p'], ['h'], ['e'], ['r'], [' '], ['a'], ['l'], ['g'], ['o'], ['r'], ['i'], ['t'], ['h'], ['m'], [' '], ['f'], ['o'], ['r'], [' '], ['t'], ['e'], ['x'], ['t'], [' '], ['e'], ['n'], ['c'], ['r'], ['y'], ['p'], ['t'], ['i'], ['o'], ['n'], [','], [' '], ['e'], ['n'], ['s'], ['u'], ['r'], ['i'], ['n'], ['g'], [' '], ['9'], ['5'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], [','], [' '], ['d'], ['e'], ['c'], ['r'], ['e'], ['a'], ['s'], ['e'], ['d'], [' '], ['v'], ['u'], ['l'], ['n'], ['e'], ['r'], ['a'], ['b'], ['i'], ['l'], ['i'], ['t'], ['y'], [' '], ['t'], ['o'], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['a'], ['t'], ['t'], ['a'], ['c'], ['k'], ['s'], [' '], ['b'], ['y'], [' '], ['5'], ['0'], [' '], [' '], ['a'], ['n'], ['d'], [' '], ['e'], ['n'], ['h'], ['a'], ['n'], ['c'], ['e'], ['d'], [' '], ['d'], ['a'], ['t'], ['a'], [' '], ['p'], ['r'], ['o'], ['t'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], ['c'], ['o'], ['m'], ['p'], ['l'], ['i'], ['a'], ['n'], ['c'], ['e'], [' '], ['b'], ['y'], [' '], ['4'], ['0'], ['.'], [' '], [' '], [' '], [' '], ['t'], ['e'], ['c'], ['h'], [' '], ['s'], ['t'], ['a'], ['c'], ['k'], [' '], ['p'], ['y'], ['t'], ['h'], ['o'], ['n'], [','], [' '], ['c'], ['r'], ['y'], ['p'], ['t'], ['o'], ['g'], ['r'], ['a'], ['p'], ['h'], ['y'], [' '], [','], [' '], ['s'], ['t'], ['e'], ['g'], ['a'], ['n'], ['o'], [' '], ['l'], ['i'], ['b'], ['r'], ['a'], ['r'], ['y'], [','], [' '], ['p'], ['y'], ['c'], ['r'], ['y'], ['p'], ['t'], ['o'], ['d'], ['o'], ['m'], ['e'], [' '], ['l'], ['i'], ['b'], ['r'], ['a'], ['r'], ['y'], ['.'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['c'], ['r'], ['y'], ['t'], ['o'], [' '], ['t'], ['r'], ['a'], ['c'], ['k'], ['e'], ['r'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['d'], ['e'], ['v'], ['e'], ['l'], ['o'], ['p'], ['e'], ['d'], [' '], ['a'], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], [' '], ['a'], ['p'], ['p'], [' '], ['u'], ['t'], ['i'], ['l'], ['i'], ['z'], ['i'], ['n'], ['g'], [' '], ['t'], ['h'], ['e'], [' '], ['c'], ['o'], ['i'], ['n'], ['g'], ['e'], ['c'], ['k'], ['o'], [' '], ['a'], ['p'], ['i'], [' '], ['t'], ['o'], [' '], ['d'], ['i'], ['s'], ['p'], ['l'], ['a'], ['y'], [' '], ['r'], ['e'], ['a'], ['l'], ['-'], ['t'], ['i'], ['m'], ['e'], [' '], ['c'], ['r'], ['y'], ['p'], ['t'], ['o'], ['c'], ['u'], ['r'], ['r'], ['e'], ['n'], ['c'], ['y'], [' '], ['p'], ['r'], ['i'], ['c'], ['e'], [' '], ['d'], ['a'], ['t'], ['a'], [','], [' '], ['i'], ['n'], ['c'], ['l'], ['u'], ['d'], ['i'], ['n'], ['g'], [' '], ['p'], ['r'], ['o'], ['f'], ['i'], ['t'], ['l'], ['o'], ['s'], ['s'], [' '], [','], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], [' '], ['u'], ['s'], ['e'], ['r'], [' '], ['s'], ['a'], ['t'], ['i'], ['s'], ['f'], ['a'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], ['r'], ['a'], ['t'], ['e'], [' '], ['o'], ['f'], [' '], ['9'], ['2'], [' '], [' '], [' '], [' '], ['e'], ['m'], ['p'], ['l'], ['o'], ['y'], ['e'], ['d'], [' '], ['i'], ['n'], ['d'], ['i'], ['c'], ['a'], ['t'], ['o'], ['r'], ['s'], [' '], ['a'], ['n'], ['d'], [' '], ['a'], [' '], ['l'], ['i'], ['n'], ['e'], [' '], ['g'], ['r'], ['a'], ['p'], ['h'], [' '], ['v'], ['i'], ['a'], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], ['-'], ['c'], ['h'], ['a'], ['r'], ['t'], ['j'], ['s'], [' '], ['t'], ['o'], [' '], ['f'], ['u'], ['r'], ['n'], ['i'], ['s'], ['h'], [' '], ['v'], ['i'], ['s'], ['u'], ['a'], ['l'], [' '], ['a'], ['n'], ['a'], ['l'], ['y'], ['t'], ['i'], ['c'], ['s'], [','], [' '], ['t'], ['h'], ['e'], ['r'], ['e'], ['b'], ['y'], [' '], ['b'], ['o'], ['l'], ['s'], ['t'], ['e'], ['r'], ['i'], ['n'], ['g'], [' '], ['w'], ['o'], ['r'], ['k'], ['f'], ['l'], ['o'], ['w'], [' '], ['e'], ['f'], ['f'], ['i'], ['c'], ['i'], ['e'], ['n'], ['c'], ['y'], [' '], ['b'], ['y'], [' '], ['3'], ['0'], [' '], [' '], ['t'], ['h'], ['r'], ['o'], ['u'], ['g'], ['h'], [' '], ['a'], ['n'], [' '], ['i'], ['n'], ['t'], ['u'], ['i'], ['t'], ['i'], ['v'], ['e'], [' '], ['i'], ['n'], ['t'], ['e'], ['r'], ['f'], ['a'], ['c'], ['e'], [' '], ['a'], ['n'], ['d'], [' '], ['f'], ['o'], ['r'], ['t'], ['i'], ['f'], ['i'], ['e'], ['d'], [' '], ['u'], ['s'], ['e'], ['r'], [' '], ['a'], ['u'], ['t'], ['h'], ['e'], ['n'], ['t'], ['i'], ['c'], ['a'], ['t'], ['i'], ['o'], ['n'], ['.'], [' '], [' '], [' '], [' '], ['t'], ['e'], ['c'], ['h'], [' '], ['s'], ['t'], ['a'], ['c'], ['k'], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], ['j'], ['s'], [','], ['m'], ['a'], ['t'], ['e'], ['r'], ['i'], ['a'], ['l'], [' '], ['u'], ['i'], [','], ['c'], ['o'], ['i'], ['n'], ['g'], ['e'], ['c'], ['k'], ['o'], [' '], ['a'], ['p'], ['i'], [' '], [' '], [' '], [' '], [' '], [' '], ['s'], ['k'], ['i'], ['l'], ['l'], ['s'], [' '], [' '], [' '], [' '], ['p'], ['r'], ['o'], ['g'], ['r'], ['a'], ['m'], ['m'], ['i'], ['n'], ['g'], [' '], ['l'], ['a'], ['n'], ['g'], ['u'], ['a'], ['g'], ['e'], ['s'], [' '], ['c'], ['+'], ['+'], [','], [' '], ['j'], ['a'], ['v'], ['a'], ['s'], ['c'], ['r'], ['i'], ['p'], ['t'], [','], [' '], ['p'], ['y'], ['t'], ['h'], ['o'], ['n'], [','], [' '], ['c'], [','], [' '], [' '], ['s'], ['q'], ['l'], [' '], [' '], [' '], [' '], ['t'], ['o'], ['o'], ['l'], ['s'], [' '], ['f'], ['r'], ['a'], ['m'], ['e'], ['w'], ['o'], ['r'], ['k'], ['s'], [' '], [' '], [' '], ['w'], ['i'], ['r'], ['e'], ['s'], ['h'], ['a'], ['r'], ['k'], [','], [' '], ['m'], ['e'], ['t'], ['a'], ['s'], ['p'], ['l'], ['o'], ['i'], ['t'], [','], [' '], ['n'], ['m'], ['a'], ['p'], [','], [' '], ['a'], ['i'], ['r'], ['c'], ['r'], ['a'], ['c'], ['k'], ['-'], ['n'], ['g'], [','], [' '], ['b'], ['u'], ['r'], ['p'], [' '], ['s'], ['u'], ['i'], ['t'], ['e'], [' '], [','], ['k'], ['a'], ['l'], ['i'], [' '], ['l'], ['i'], ['n'], ['u'], ['x'], [','], [' '], ['h'], ['a'], ['s'], ['h'], ['c'], ['a'], ['t'], [','], [' '], ['o'], ['w'], ['a'], ['s'], ['p'], [' '], ['z'], ['a'], ['p'], [','], ['r'], ['e'], ['a'], ['c'], ['t'], ['.'], ['j'], ['s'], [','], [' '], ['t'], ['a'], ['i'], ['l'], ['w'], ['i'], ['n'], ['d'], [' '], ['c'], ['s'], ['s'], [','], [' '], [' '], ['m'], ['o'], ['n'], ['g'], ['o'], ['d'], ['b'], [','], ['f'], ['i'], ['r'], ['e'], ['b'], ['a'], ['s'], ['e'], [','], [' '], ['g'], ['i'], ['t'], [','], [' '], ['g'], ['i'], ['t'], ['-'], ['h'], ['u'], ['b'], ['.'], [' '], [' '], [' '], [' '], ['c'], ['o'], ['u'], ['r'], ['s'], ['e'], ['s'], [' '], [' '], ['c'], ['o'], ['m'], ['p'], ['u'], ['t'], ['e'], ['r'], [' '], ['n'], ['e'], ['t'], ['w'], ['o'], ['r'], ['k'], ['i'], ['n'], ['g'], [' '], [','], ['w'], ['e'], ['b'], ['-'], ['p'], ['e'], ['n'], ['t'], ['e'], ['s'], ['t'], ['i'], ['n'], ['g'], [' '], [','], ['d'], ['a'], ['t'], ['a'], ['b'], ['a'], ['s'], ['e'], [' '], ['m'], ['a'], ['n'], ['a'], ['g'], ['e'], ['m'], ['e'], ['n'], ['t'], [','], [' '], ['d'], ['a'], ['t'], ['a'], [' '], ['s'], ['t'], ['r'], ['u'], ['c'], ['t'], ['u'], ['r'], ['e'], ['s'], [','], [' '], ['a'], ['l'], ['g'], ['o'], ['r'], ['i'], ['t'], ['h'], ['m'], ['s'], [','], [' '], ['w'], ['e'], ['b'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [','], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], ['.'], [' '], [' '], [' '], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['o'], ['n'], [' '], ['o'], ['f'], [' '], ['r'], ['e'], ['s'], ['p'], ['o'], ['n'], ['s'], ['i'], ['b'], ['i'], ['l'], ['y'], [' '], [' '], [' '], [' '], [' '], [' '], [' '], ['o'], ['w'], ['a'], ['s'], ['p'], [' '], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['c'], ['a'], ['l'], [' '], ['h'], ['e'], ['a'], ['d'], [' '], [' '], ['r'], ['e'], ['s'], ['p'], ['o'], ['n'], ['s'], ['i'], ['b'], ['l'], ['e'], [' '], ['f'], ['o'], ['r'], [' '], ['l'], ['e'], ['a'], ['d'], ['i'], ['n'], ['g'], [' '], ['a'], ['n'], ['d'], [' '], ['t'], ['e'], ['a'], ['c'], ['h'], ['i'], ['n'], ['g'], [' '], ['o'], ['v'], ['e'], ['r'], [' '], ['4'], ['0'], ['0'], [' '], ['s'], ['t'], ['u'], ['d'], ['e'], ['n'], ['t'], [' '], ['f'], ['u'], ['n'], ['d'], ['a'], ['m'], ['e'], ['n'], ['t'], ['a'], ['l'], [' '], ['o'], ['f'], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], ['.'], [' '], [' '], [' '], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['c'], ['a'], ['l'], [' '], ['h'], ['e'], ['a'], ['d'], [' '], [' '], ['e'], ['n'], ['g'], ['e'], ['r'], ['g'], ['i'], ['a'], [' '], [' '], ['d'], ['e'], ['v'], ['e'], ['l'], ['o'], ['p'], ['e'], ['d'], [' '], ['t'], ['h'], ['e'], [' '], ['o'], ['f'], ['f'], ['i'], ['c'], ['i'], ['a'], ['l'], [' '], ['w'], ['e'], ['b'], ['s'], ['i'], ['t'], ['e'], [' '], ['f'], ['o'], ['r'], [' '], ['c'], ['o'], ['l'], ['l'], ['e'], ['g'], ['e'], [' '], ['s'], ['p'], ['o'], ['r'], ['t'], [' '], ['f'], ['e'], ['s'], ['t'], [' '], ['e'], ['n'], ['e'], ['r'], ['g'], ['i'], ['a'], ['.'], [' '], [' '], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['m'], ['e'], ['n'], ['t'], ['s'], [' '], [' '], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['d'], [' '], ['f'], ['i'], ['n'], ['a'], ['l'], ['i'], ['s'], ['t'], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['o'], ['n'], [' '], ['i'], ['n'], [' '], ['r'], ['a'], ['j'], ['a'], ['s'], ['t'], ['h'], ['a'], ['n'], [' '], ['p'], ['o'], ['l'], ['i'], ['c'], ['e'], [' '], ['h'], ['a'], ['c'], ['k'], ['a'], ['t'], ['h'], ['o'], ['n'], [' '], ['1'], ['.'], ['0'], [','], [' '], ['e'], ['x'], ['h'], ['i'], ['b'], ['i'], ['t'], ['i'], ['n'], ['g'], [' '], ['i'], ['n'], ['n'], ['o'], ['v'], ['a'], ['t'], ['i'], ['v'], ['e'], [' '], ['p'], ['r'], ['o'], ['b'], ['l'], ['e'], ['m'], ['-'], ['s'], ['o'], ['l'], ['v'], ['i'], ['n'], ['g'], [' '], ['c'], ['a'], ['p'], ['a'], ['b'], ['i'], ['l'], ['i'], ['t'], ['i'], ['e'], ['s'], [' '], ['i'], ['n'], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], ['.'], [' '], [' '], [' '], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['e'], ['d'], [' '], ['1'], ['0'], ['t'], ['h'], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['o'], ['n'], [' '], ['i'], ['n'], [' '], ['t'], ['r'], ['i'], ['-'], ['n'], ['i'], ['t'], [' '], ['h'], ['a'], ['c'], ['k'], ['a'], ['t'], ['h'], ['o'], ['n'], [','], [' '], ['s'], ['h'], ['o'], ['w'], ['c'], ['a'], ['s'], ['i'], ['n'], ['g'], [' '], ['p'], ['r'], ['o'], ['b'], ['l'], ['e'], ['m'], ['-'], ['s'], ['o'], ['l'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], ['n'], ['d'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['c'], ['a'], ['l'], [' '], ['s'], ['k'], ['i'], ['l'], ['l'], ['s'], ['.'], [' '], [' '], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['d'], [' '], ['r'], ['a'], ['n'], ['k'], [' '], ['2'], [' '], ['('], ['t'], ['i'], ['l'], ['l'], [' '], ['d'], ['a'], ['t'], ['e'], [')'], [' '], ['i'], ['n'], [' '], ['i'], ['t'], [' '], ['d'], ['e'], ['p'], ['a'], ['r'], ['t'], ['m'], ['e'], ['n'], ['t'], [' '], ['s'], ['t'], ['u'], ['d'], ['e'], ['n'], ['t'], ['s'], [' '], ['i'], ['n'], [' '], ['t'], ['h'], ['e'], [' '], ['c'], ['s'], ['e'], ['.'], [' '], [' '], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['d'], [' '], ['a'], [' '], ['t'], ['o'], ['p'], [' '], ['2'], [' '], ['r'], ['a'], ['n'], ['k'], [' '], ['i'], ['n'], [' '], ['t'], ['h'], ['e'], [' '], ['i'], ['i'], ['t'], ['-'], ['j'], ['e'], ['e'], [' '], ['a'], ['d'], ['v'], ['a'], ['n'], ['c'], ['e'], ['d'], [' '], ['2'], ['0'], ['2'], ['1'], [' '], ['e'], ['x'], ['a'], ['m'], [' '], [' ']]\n",
      "[['d'], ['e'], ['e'], ['p'], ['a'], ['n'], ['k'], [' '], ['s'], ['i'], ['n'], ['g'], ['h'], [' '], ['f'], ['i'], ['n'], ['a'], ['l'], [' '], ['y'], ['e'], ['a'], ['r'], [','], [' '], ['i'], ['n'], ['f'], ['o'], ['r'], ['m'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [' '], [' '], ['+'], ['9'], ['1'], ['-'], ['8'], ['1'], ['6'], ['8'], ['0'], ['5'], ['3'], ['3'], ['9'], ['4'], [' '], [' '], ['d'], ['e'], ['e'], ['p'], ['a'], ['n'], ['k'], ['s'], ['i'], ['n'], ['g'], ['h'], ['0'], ['1'], ['g'], ['m'], ['a'], ['i'], ['l'], ['.'], ['c'], ['o'], ['m'], [' '], [' '], ['l'], ['i'], ['n'], ['k'], ['e'], ['d'], ['i'], ['n'], [' '], [' '], ['g'], ['i'], ['t'], ['h'], ['u'], ['b'], [' '], ['e'], ['d'], ['u'], ['c'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['r'], ['a'], ['j'], ['i'], ['v'], [' '], ['g'], ['a'], ['n'], ['d'], ['h'], ['i'], [' '], ['i'], ['n'], ['s'], ['t'], ['i'], ['t'], ['u'], ['t'], ['e'], [' '], ['o'], ['f'], [' '], ['p'], ['e'], ['t'], ['r'], ['o'], ['l'], ['e'], ['u'], ['m'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [' '], ['('], ['r'], ['g'], ['i'], ['p'], ['t'], [')'], [','], [' '], ['a'], ['m'], ['e'], ['t'], ['h'], ['i'], [','], [' '], ['u'], ['t'], ['t'], ['a'], ['r'], [' '], ['p'], ['r'], ['a'], ['d'], ['e'], ['s'], ['h'], [' '], ['2'], ['0'], ['2'], ['1'], ['-'], ['2'], ['0'], ['2'], ['5'], [' '], ['b'], ['t'], ['e'], ['c'], ['h'], [' '], ['i'], ['n'], [' '], ['i'], ['n'], ['f'], ['o'], ['r'], ['m'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [' '], ['('], ['c'], ['p'], ['i'], [' '], ['9'], ['.'], ['1'], ['2'], [')'], [' '], ['d'], ['a'], ['v'], [' '], ['p'], ['u'], ['b'], ['l'], ['i'], ['c'], [' '], ['s'], ['c'], ['h'], ['o'], ['o'], ['l'], [' '], [','], [' '], ['a'], ['m'], ['b'], ['a'], ['l'], ['a'], [' '], [','], [' '], ['h'], ['a'], ['r'], ['y'], ['a'], ['n'], ['a'], [' '], ['2'], ['0'], ['2'], ['1'], [' '], ['i'], ['n'], ['t'], ['e'], ['r'], ['m'], ['e'], ['d'], ['i'], ['a'], ['t'], ['e'], [' '], ['('], ['s'], ['c'], ['o'], ['r'], ['e'], [' '], ['9'], ['1'], ['.'], ['0'], ['2'], [')'], [' '], ['d'], ['a'], ['v'], [' '], ['p'], ['u'], ['b'], ['l'], ['i'], ['c'], [' '], ['s'], ['c'], ['h'], ['o'], ['o'], ['l'], [','], [' '], ['a'], ['m'], ['b'], ['a'], ['l'], ['a'], [','], [' '], ['h'], ['a'], ['r'], ['y'], ['a'], ['n'], ['a'], [' '], ['2'], ['0'], ['1'], ['9'], [' '], ['m'], ['a'], ['t'], ['r'], ['i'], ['c'], ['u'], ['l'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['('], ['s'], ['c'], ['o'], ['r'], ['e'], [' '], ['9'], ['7'], ['.'], ['6'], ['0'], [')'], [' '], ['w'], ['o'], ['r'], ['k'], [' '], ['e'], ['x'], ['p'], ['e'], ['r'], ['i'], ['e'], ['n'], ['c'], ['e'], [' '], ['s'], ['a'], ['l'], ['a'], ['-'], [' '], ['k'], ['a'], ['r'], ['t'], [' '], [' '], ['r'], ['e'], ['m'], ['o'], ['t'], ['e'], [' '], ['('], ['s'], ['d'], ['e'], [' '], ['i'], ['n'], ['t'], ['e'], ['r'], ['n'], [')'], [' '], ['m'], ['a'], ['y'], ['2'], ['0'], ['2'], ['4'], [' '], ['p'], ['r'], ['o'], ['j'], ['e'], ['c'], ['t'], ['s'], [' '], ['w'], ['e'], ['b'], [' '], ['e'], ['x'], ['t'], ['e'], ['n'], ['s'], ['i'], ['o'], ['n'], [' '], ['f'], ['o'], ['r'], [' '], ['m'], ['a'], ['l'], ['i'], ['c'], ['i'], ['o'], ['u'], ['s'], [' '], ['u'], ['r'], ['l'], [' '], ['d'], ['e'], ['t'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], ['('], ['o'], ['n'], ['g'], ['o'], ['i'], ['n'], ['g'], [')'], [' '], [' '], ['e'], ['n'], ['g'], ['i'], ['n'], ['e'], ['e'], ['r'], ['e'], ['d'], [' '], ['a'], [' '], ['w'], ['e'], ['b'], [' '], ['e'], ['x'], ['t'], ['e'], ['n'], ['s'], ['i'], ['o'], ['n'], [' '], ['t'], ['h'], ['a'], ['t'], [' '], ['d'], ['e'], ['t'], ['e'], ['c'], ['t'], ['s'], [' '], ['m'], ['a'], ['l'], ['i'], ['c'], ['i'], ['o'], ['u'], ['s'], [' '], ['u'], ['r'], ['l'], ['s'], [' '], ['o'], ['n'], [' '], ['w'], ['e'], ['b'], ['p'], ['a'], ['g'], ['e'], ['s'], [','], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], [' '], ['9'], ['9'], [' '], ['s'], ['u'], ['c'], ['c'], ['e'], ['s'], ['s'], [' '], ['r'], ['a'], ['t'], ['e'], [' '], ['i'], ['n'], [' '], ['i'], ['d'], ['e'], ['n'], ['t'], ['i'], ['f'], ['y'], ['i'], ['n'], ['g'], [' '], ['t'], ['h'], ['r'], ['e'], ['a'], ['t'], ['s'], [' '], ['a'], ['n'], ['d'], [' '], ['e'], ['n'], ['s'], ['u'], ['r'], ['i'], ['n'], ['g'], [' '], ['u'], ['s'], ['e'], ['r'], [' '], ['s'], ['a'], ['f'], ['e'], ['t'], ['y'], ['.'], [' '], [' '], ['l'], ['e'], ['v'], ['e'], ['r'], ['a'], ['g'], ['e'], ['d'], [' '], ['a'], ['d'], ['v'], ['a'], ['n'], ['c'], ['e'], ['d'], [' '], ['d'], ['e'], ['e'], ['p'], [' '], ['l'], ['e'], ['a'], ['r'], ['n'], ['i'], ['n'], ['g'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['q'], ['u'], ['e'], ['s'], [','], [' '], ['r'], ['e'], ['s'], ['u'], ['l'], ['t'], ['i'], ['n'], ['g'], [' '], ['i'], ['n'], [' '], ['a'], [' '], ['9'], ['5'], [' '], ['a'], ['c'], ['c'], ['u'], ['r'], ['a'], ['c'], ['y'], [' '], ['r'], ['a'], ['t'], ['e'], [' '], ['f'], ['o'], ['r'], [' '], ['m'], ['a'], ['l'], ['i'], ['c'], ['i'], ['o'], ['u'], ['s'], [' '], ['u'], ['r'], ['l'], [' '], ['d'], ['e'], ['t'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [','], [' '], ['s'], ['i'], ['g'], ['n'], ['i'], ['f'], ['i'], ['c'], ['a'], ['n'], ['t'], ['l'], ['y'], [' '], ['r'], ['e'], ['d'], ['u'], ['c'], ['i'], ['n'], ['g'], [' '], ['f'], ['a'], ['l'], ['s'], ['e'], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['v'], ['e'], ['s'], [' '], ['a'], ['n'], ['d'], [' '], ['n'], ['e'], ['g'], ['a'], ['t'], ['i'], ['v'], ['e'], ['s'], ['.'], [' '], [' '], ['l'], ['e'], ['v'], ['e'], ['r'], ['a'], ['g'], ['e'], ['d'], [' '], ['f'], ['e'], ['d'], ['e'], ['r'], ['a'], ['t'], ['e'], ['d'], [' '], ['l'], ['e'], ['a'], ['r'], ['n'], ['i'], ['n'], ['g'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['q'], ['u'], ['e'], ['s'], [' '], ['t'], ['o'], [' '], ['f'], ['a'], ['c'], ['i'], ['l'], ['i'], ['t'], ['a'], ['t'], ['e'], [' '], ['d'], ['e'], ['c'], ['e'], ['n'], ['t'], ['r'], ['a'], ['l'], ['i'], ['z'], ['e'], ['d'], [' '], ['d'], ['a'], ['t'], ['a'], [' '], ['c'], ['o'], ['l'], ['l'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], ['a'], ['n'], ['d'], [' '], ['t'], ['r'], ['a'], ['i'], ['n'], ['i'], ['n'], ['g'], [','], [' '], ['e'], ['n'], ['a'], ['b'], ['l'], ['i'], ['n'], ['g'], [' '], ['a'], [' '], ['c'], ['o'], ['l'], ['l'], ['a'], ['b'], ['o'], ['r'], ['a'], ['t'], ['i'], ['v'], ['e'], [' '], ['a'], ['n'], ['d'], [' '], ['p'], ['r'], ['i'], ['v'], ['a'], ['c'], ['y'], ['-'], ['p'], ['r'], ['e'], ['s'], ['e'], ['r'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], ['p'], ['p'], ['r'], ['o'], ['a'], ['c'], ['h'], [' '], ['t'], ['o'], [' '], ['m'], ['o'], ['d'], ['e'], ['l'], [' '], ['d'], ['e'], ['v'], ['e'], ['l'], ['o'], ['p'], ['m'], ['e'], ['n'], ['t'], ['.'], [' '], [' '], ['t'], ['e'], ['c'], ['h'], [' '], ['s'], ['t'], ['a'], ['c'], ['k'], [' '], ['t'], ['e'], ['n'], ['s'], ['o'], ['r'], ['f'], ['l'], ['o'], ['w'], [','], [' '], ['p'], ['y'], ['s'], ['y'], ['f'], ['t'], [','], [' '], ['j'], ['a'], ['v'], ['a'], ['s'], ['c'], ['r'], ['i'], ['p'], ['t'], [','], ['j'], ['w'], ['t'], [','], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], ['-'], ['j'], ['s'], [','], [' '], ['t'], ['w'], ['a'], ['i'], ['l'], ['w'], ['i'], ['n'], ['d'], ['-'], ['c'], ['s'], ['s'], [' '], [','], ['n'], ['o'], ['d'], ['e'], ['-'], ['j'], ['s'], [' '], ['i'], ['m'], ['a'], ['g'], ['e'], [' '], ['s'], ['t'], ['e'], ['g'], ['a'], ['n'], ['o'], ['g'], ['r'], ['a'], ['p'], ['h'], ['y'], [' '], [' '], ['e'], ['n'], ['g'], ['i'], ['n'], ['e'], ['e'], ['r'], ['e'], ['d'], [' '], ['a'], [' '], ['s'], ['o'], ['f'], ['t'], ['w'], ['a'], ['r'], ['e'], [' '], ['a'], ['p'], ['p'], ['l'], ['i'], ['c'], ['a'], ['t'], ['i'], ['o'], ['n'], [' '], ['f'], ['o'], ['r'], [' '], ['i'], ['m'], ['a'], ['g'], ['e'], [' '], ['s'], ['t'], ['e'], ['g'], ['a'], ['n'], ['o'], ['g'], ['r'], ['a'], ['p'], ['h'], ['y'], [' '], ['u'], ['t'], ['i'], ['l'], ['i'], ['z'], ['i'], ['n'], ['g'], [' '], ['t'], ['h'], ['e'], [' '], ['l'], ['s'], ['b'], [' '], ['a'], ['l'], ['g'], ['o'], ['r'], ['i'], ['t'], ['h'], ['m'], [','], [' '], ['e'], ['n'], ['a'], ['b'], ['l'], ['i'], ['n'], ['g'], [' '], ['t'], ['e'], ['x'], ['t'], [' '], ['e'], ['m'], ['b'], ['e'], ['d'], ['d'], ['i'], ['n'], ['g'], [' '], ['c'], ['a'], ['p'], ['a'], ['c'], ['i'], ['t'], ['y'], [' '], ['o'], ['f'], [' '], ['u'], ['p'], [' '], ['t'], ['o'], [' '], ['2'], ['5'], ['.'], [' '], [' '], ['i'], ['n'], ['t'], ['e'], ['g'], ['r'], ['a'], ['t'], ['e'], ['d'], [' '], ['a'], [' '], ['r'], ['o'], ['b'], ['u'], ['s'], ['t'], [' '], ['c'], ['i'], ['p'], ['h'], ['e'], ['r'], [' '], ['a'], ['l'], ['g'], ['o'], ['r'], ['i'], ['t'], ['h'], ['m'], [' '], ['f'], ['o'], ['r'], [' '], ['t'], ['e'], ['x'], ['t'], [' '], ['e'], ['n'], ['c'], ['r'], ['y'], ['p'], ['t'], ['i'], ['o'], ['n'], [','], [' '], ['e'], ['n'], ['s'], ['u'], ['r'], ['i'], ['n'], ['g'], [' '], ['9'], ['5'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], [','], [' '], ['d'], ['e'], ['c'], ['r'], ['e'], ['a'], ['s'], ['e'], ['d'], [' '], ['v'], ['u'], ['l'], ['n'], ['e'], ['r'], ['a'], ['b'], ['i'], ['l'], ['i'], ['t'], ['y'], [' '], ['t'], ['o'], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['a'], ['t'], ['t'], ['a'], ['c'], ['k'], ['s'], [' '], ['b'], ['y'], [' '], ['5'], ['0'], [' '], ['a'], ['n'], ['d'], [' '], ['e'], ['n'], ['h'], ['a'], ['n'], ['c'], ['e'], ['d'], [' '], ['d'], ['a'], ['t'], ['a'], [' '], ['p'], ['r'], ['o'], ['t'], ['e'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], ['c'], ['o'], ['m'], ['p'], ['l'], ['i'], ['a'], ['n'], ['c'], ['e'], [' '], ['b'], ['y'], [' '], ['4'], ['0'], ['.'], [' '], [' '], ['t'], ['e'], ['c'], ['h'], [' '], ['s'], ['t'], ['a'], ['c'], ['k'], [' '], ['p'], ['y'], ['t'], ['h'], ['o'], ['n'], [','], [' '], ['c'], ['r'], ['y'], ['p'], ['t'], ['o'], ['g'], ['r'], ['a'], ['p'], ['h'], ['y'], [' '], [','], [' '], ['s'], ['t'], ['e'], ['g'], ['a'], ['n'], ['o'], [' '], ['l'], ['i'], ['b'], ['r'], ['a'], ['r'], ['y'], [','], [' '], ['p'], ['y'], ['c'], ['r'], ['y'], ['p'], ['t'], ['o'], ['d'], ['o'], ['m'], ['e'], [' '], ['l'], ['i'], ['b'], ['r'], ['a'], ['r'], ['y'], ['.'], [' '], ['c'], ['r'], ['y'], ['t'], ['o'], [' '], ['t'], ['r'], ['a'], ['c'], ['k'], ['e'], ['r'], [' '], [' '], ['d'], ['e'], ['v'], ['e'], ['l'], ['o'], ['p'], ['e'], ['d'], [' '], ['a'], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], [' '], ['a'], ['p'], ['p'], [' '], ['u'], ['t'], ['i'], ['l'], ['i'], ['z'], ['i'], ['n'], ['g'], [' '], ['t'], ['h'], ['e'], [' '], ['c'], ['o'], ['i'], ['n'], ['g'], ['e'], ['c'], ['k'], ['o'], [' '], ['a'], ['p'], ['i'], [' '], ['t'], ['o'], [' '], ['d'], ['i'], ['s'], ['p'], ['l'], ['a'], ['y'], [' '], ['r'], ['e'], ['a'], ['l'], ['-'], ['t'], ['i'], ['m'], ['e'], [' '], ['c'], ['r'], ['y'], ['p'], ['t'], ['o'], ['c'], ['u'], ['r'], ['r'], ['e'], ['n'], ['c'], ['y'], [' '], ['p'], ['r'], ['i'], ['c'], ['e'], [' '], ['d'], ['a'], ['t'], ['a'], [','], [' '], ['i'], ['n'], ['c'], ['l'], ['u'], ['d'], ['i'], ['n'], ['g'], [' '], ['p'], ['r'], ['o'], ['f'], ['i'], ['t'], ['l'], ['o'], ['s'], ['s'], [' '], [','], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], [' '], ['u'], ['s'], ['e'], ['r'], [' '], ['s'], ['a'], ['t'], ['i'], ['s'], ['f'], ['a'], ['c'], ['t'], ['i'], ['o'], ['n'], [' '], ['r'], ['a'], ['t'], ['e'], [' '], ['o'], ['f'], [' '], ['9'], ['2'], [' '], [' '], ['e'], ['m'], ['p'], ['l'], ['o'], ['y'], ['e'], ['d'], [' '], ['i'], ['n'], ['d'], ['i'], ['c'], ['a'], ['t'], ['o'], ['r'], ['s'], [' '], ['a'], ['n'], ['d'], [' '], ['a'], [' '], ['l'], ['i'], ['n'], ['e'], [' '], ['g'], ['r'], ['a'], ['p'], ['h'], [' '], ['v'], ['i'], ['a'], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], ['-'], ['c'], ['h'], ['a'], ['r'], ['t'], ['j'], ['s'], [' '], ['t'], ['o'], [' '], ['f'], ['u'], ['r'], ['n'], ['i'], ['s'], ['h'], [' '], ['v'], ['i'], ['s'], ['u'], ['a'], ['l'], [' '], ['a'], ['n'], ['a'], ['l'], ['y'], ['t'], ['i'], ['c'], ['s'], [','], [' '], ['t'], ['h'], ['e'], ['r'], ['e'], ['b'], ['y'], [' '], ['b'], ['o'], ['l'], ['s'], ['t'], ['e'], ['r'], ['i'], ['n'], ['g'], [' '], ['w'], ['o'], ['r'], ['k'], ['f'], ['l'], ['o'], ['w'], [' '], ['e'], ['f'], ['f'], ['i'], ['c'], ['i'], ['e'], ['n'], ['c'], ['y'], [' '], ['b'], ['y'], [' '], ['3'], ['0'], [' '], ['t'], ['h'], ['r'], ['o'], ['u'], ['g'], ['h'], [' '], ['a'], ['n'], [' '], ['i'], ['n'], ['t'], ['u'], ['i'], ['t'], ['i'], ['v'], ['e'], [' '], ['i'], ['n'], ['t'], ['e'], ['r'], ['f'], ['a'], ['c'], ['e'], [' '], ['a'], ['n'], ['d'], [' '], ['f'], ['o'], ['r'], ['t'], ['i'], ['f'], ['i'], ['e'], ['d'], [' '], ['u'], ['s'], ['e'], ['r'], [' '], ['a'], ['u'], ['t'], ['h'], ['e'], ['n'], ['t'], ['i'], ['c'], ['a'], ['t'], ['i'], ['o'], ['n'], ['.'], [' '], [' '], ['t'], ['e'], ['c'], ['h'], [' '], ['s'], ['t'], ['a'], ['c'], ['k'], [' '], ['r'], ['e'], ['a'], ['c'], ['t'], ['j'], ['s'], [','], ['m'], ['a'], ['t'], ['e'], ['r'], ['i'], ['a'], ['l'], [' '], ['u'], ['i'], [','], ['c'], ['o'], ['i'], ['n'], ['g'], ['e'], ['c'], ['k'], ['o'], [' '], ['a'], ['p'], ['i'], [' '], ['s'], ['k'], ['i'], ['l'], ['l'], ['s'], [' '], ['p'], ['r'], ['o'], ['g'], ['r'], ['a'], ['m'], ['m'], ['i'], ['n'], ['g'], [' '], ['l'], ['a'], ['n'], ['g'], ['u'], ['a'], ['g'], ['e'], ['s'], [' '], ['c'], ['+'], ['+'], [','], [' '], ['j'], ['a'], ['v'], ['a'], ['s'], ['c'], ['r'], ['i'], ['p'], ['t'], [','], [' '], ['p'], ['y'], ['t'], ['h'], ['o'], ['n'], [','], [' '], ['c'], [','], [' '], ['s'], ['q'], ['l'], [' '], ['t'], ['o'], ['o'], ['l'], ['s'], [' '], ['f'], ['r'], ['a'], ['m'], ['e'], ['w'], ['o'], ['r'], ['k'], ['s'], [' '], [' '], ['w'], ['i'], ['r'], ['e'], ['s'], ['h'], ['a'], ['r'], ['k'], [','], [' '], ['m'], ['e'], ['t'], ['a'], ['s'], ['p'], ['l'], ['o'], ['i'], ['t'], [','], [' '], ['n'], ['m'], ['a'], ['p'], [','], [' '], ['a'], ['i'], ['r'], ['c'], ['r'], ['a'], ['c'], ['k'], ['-'], ['n'], ['g'], [','], [' '], ['b'], ['u'], ['r'], ['p'], [' '], ['s'], ['u'], ['i'], ['t'], ['e'], [' '], [','], ['k'], ['a'], ['l'], ['i'], [' '], ['l'], ['i'], ['n'], ['u'], ['x'], [','], [' '], ['h'], ['a'], ['s'], ['h'], ['c'], ['a'], ['t'], [','], [' '], ['o'], ['w'], ['a'], ['s'], ['p'], [' '], ['z'], ['a'], ['p'], [','], ['r'], ['e'], ['a'], ['c'], ['t'], ['.'], ['j'], ['s'], [','], [' '], ['t'], ['a'], ['i'], ['l'], ['w'], ['i'], ['n'], ['d'], [' '], ['c'], ['s'], ['s'], [','], [' '], ['m'], ['o'], ['n'], ['g'], ['o'], ['d'], ['b'], [','], ['f'], ['i'], ['r'], ['e'], ['b'], ['a'], ['s'], ['e'], [','], [' '], ['g'], ['i'], ['t'], [','], [' '], ['g'], ['i'], ['t'], ['-'], ['h'], ['u'], ['b'], ['.'], [' '], ['c'], ['o'], ['u'], ['r'], ['s'], ['e'], ['s'], [' '], [' '], ['c'], ['o'], ['m'], ['p'], ['u'], ['t'], ['e'], ['r'], [' '], ['n'], ['e'], ['t'], ['w'], ['o'], ['r'], ['k'], ['i'], ['n'], ['g'], [' '], [','], ['w'], ['e'], ['b'], ['-'], ['p'], ['e'], ['n'], ['t'], ['e'], ['s'], ['t'], ['i'], ['n'], ['g'], [' '], [','], ['d'], ['a'], ['t'], ['a'], ['b'], ['a'], ['s'], ['e'], [' '], ['m'], ['a'], ['n'], ['a'], ['g'], ['e'], ['m'], ['e'], ['n'], ['t'], [','], [' '], ['d'], ['a'], ['t'], ['a'], [' '], ['s'], ['t'], ['r'], ['u'], ['c'], ['t'], ['u'], ['r'], ['e'], ['s'], [','], [' '], ['a'], ['l'], ['g'], ['o'], ['r'], ['i'], ['t'], ['h'], ['m'], ['s'], [','], [' '], ['w'], ['e'], ['b'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['y'], [','], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], ['.'], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['o'], ['n'], [' '], ['o'], ['f'], [' '], ['r'], ['e'], ['s'], ['p'], ['o'], ['n'], ['s'], ['i'], ['b'], ['i'], ['l'], ['y'], [' '], [' '], [' '], ['o'], ['w'], ['a'], ['s'], ['p'], [' '], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['c'], ['a'], ['l'], [' '], ['h'], ['e'], ['a'], ['d'], [' '], [' '], ['r'], ['e'], ['s'], ['p'], ['o'], ['n'], ['s'], ['i'], ['b'], ['l'], ['e'], [' '], ['f'], ['o'], ['r'], [' '], ['l'], ['e'], ['a'], ['d'], ['i'], ['n'], ['g'], [' '], ['a'], ['n'], ['d'], [' '], ['t'], ['e'], ['a'], ['c'], ['h'], ['i'], ['n'], ['g'], [' '], ['o'], ['v'], ['e'], ['r'], [' '], ['4'], ['0'], ['0'], [' '], ['s'], ['t'], ['u'], ['d'], ['e'], ['n'], ['t'], [' '], ['f'], ['u'], ['n'], ['d'], ['a'], ['m'], ['e'], ['n'], ['t'], ['a'], ['l'], [' '], ['o'], ['f'], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], ['.'], [' '], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['c'], ['a'], ['l'], [' '], ['h'], ['e'], ['a'], ['d'], [' '], [' '], ['e'], ['n'], ['g'], ['e'], ['r'], ['g'], ['i'], ['a'], [' '], ['d'], ['e'], ['v'], ['e'], ['l'], ['o'], ['p'], ['e'], ['d'], [' '], ['t'], ['h'], ['e'], [' '], ['o'], ['f'], ['f'], ['i'], ['c'], ['i'], ['a'], ['l'], [' '], ['w'], ['e'], ['b'], ['s'], ['i'], ['t'], ['e'], [' '], ['f'], ['o'], ['r'], [' '], ['c'], ['o'], ['l'], ['l'], ['e'], ['g'], ['e'], [' '], ['s'], ['p'], ['o'], ['r'], ['t'], [' '], ['f'], ['e'], ['s'], ['t'], [' '], ['e'], ['n'], ['e'], ['r'], ['g'], ['i'], ['a'], ['.'], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['m'], ['e'], ['n'], ['t'], ['s'], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['d'], [' '], ['f'], ['i'], ['n'], ['a'], ['l'], ['i'], ['s'], ['t'], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['o'], ['n'], [' '], ['i'], ['n'], [' '], ['r'], ['a'], ['j'], ['a'], ['s'], ['t'], ['h'], ['a'], ['n'], [' '], ['p'], ['o'], ['l'], ['i'], ['c'], ['e'], [' '], ['h'], ['a'], ['c'], ['k'], ['a'], ['t'], ['h'], ['o'], ['n'], [' '], ['1'], ['.'], ['0'], [','], [' '], ['e'], ['x'], ['h'], ['i'], ['b'], ['i'], ['t'], ['i'], ['n'], ['g'], [' '], ['i'], ['n'], ['n'], ['o'], ['v'], ['a'], ['t'], ['i'], ['v'], ['e'], [' '], ['p'], ['r'], ['o'], ['b'], ['l'], ['e'], ['m'], ['-'], ['s'], ['o'], ['l'], ['v'], ['i'], ['n'], ['g'], [' '], ['c'], ['a'], ['p'], ['a'], ['b'], ['i'], ['l'], ['i'], ['t'], ['i'], ['e'], ['s'], [' '], ['i'], ['n'], [' '], ['c'], ['y'], ['b'], ['e'], ['r'], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['i'], ['t'], ['y'], ['.'], [' '], [' '], ['s'], ['e'], ['c'], ['u'], ['r'], ['e'], ['d'], [' '], ['1'], ['0'], ['t'], ['h'], [' '], ['p'], ['o'], ['s'], ['i'], ['t'], ['i'], ['o'], ['n'], [' '], ['i'], ['n'], [' '], ['t'], ['r'], ['i'], ['-'], ['n'], ['i'], ['t'], [' '], ['h'], ['a'], ['c'], ['k'], ['a'], ['t'], ['h'], ['o'], ['n'], [','], [' '], ['s'], ['h'], ['o'], ['w'], ['c'], ['a'], ['s'], ['i'], ['n'], ['g'], [' '], ['p'], ['r'], ['o'], ['b'], ['l'], ['e'], ['m'], ['-'], ['s'], ['o'], ['l'], ['v'], ['i'], ['n'], ['g'], [' '], ['a'], ['n'], ['d'], [' '], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['c'], ['a'], ['l'], [' '], ['s'], ['k'], ['i'], ['l'], ['l'], ['s'], ['.'], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['d'], [' '], ['r'], ['a'], ['n'], ['k'], [' '], ['2'], [' '], ['('], ['t'], ['i'], ['l'], ['l'], [' '], ['d'], ['a'], ['t'], ['e'], [')'], [' '], ['i'], ['n'], [' '], ['i'], ['t'], [' '], ['d'], ['e'], ['p'], ['a'], ['r'], ['t'], ['m'], ['e'], ['n'], ['t'], [' '], ['s'], ['t'], ['u'], ['d'], ['e'], ['n'], ['t'], ['s'], [' '], ['i'], ['n'], [' '], ['t'], ['h'], ['e'], [' '], ['c'], ['s'], ['e'], ['.'], [' '], [' '], ['a'], ['c'], ['h'], ['i'], ['e'], ['v'], ['e'], ['d'], [' '], ['a'], [' '], ['t'], ['o'], ['p'], [' '], ['2'], [' '], ['r'], ['a'], ['n'], ['k'], [' '], ['i'], ['n'], [' '], ['t'], ['h'], ['e'], [' '], ['i'], ['i'], ['t'], ['-'], ['j'], ['e'], ['e'], [' '], ['a'], ['d'], ['v'], ['a'], ['n'], ['c'], ['e'], ['d'], [' '], ['2'], ['0'], ['2'], ['1'], [' '], ['e'], ['x'], ['a'], ['m']] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract, preprocess text, and split into sentences\n",
    "resumes = resume_text\n",
    "job_descriptions = jd_text \n",
    "\n",
    "print(resumes)\n",
    "print(job_descriptions, \"\\n\\n\")\n",
    "\n",
    "resume_sentences = [split_into_sentences_spacy(resume) for resume in resumes]\n",
    "job_description_sentences = [split_into_sentences_spacy(jd) for jd in job_descriptions]\n",
    "\n",
    "print(resume_sentences)\n",
    "print(job_description_sentences, \"\\n\\n\")\n",
    "\n",
    "# Flatten lists of sentences\n",
    "flat_resume_sentences = [sentence for sublist in resume_sentences for sentence in sublist]\n",
    "flat_job_description_sentences = [sentence for sublist in job_description_sentences for sentence in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9539ac4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Encode sentences in the resume and job description\u001b[39;00m\n\u001b[0;32m      4\u001b[0m resume_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(flat_resume_sentences)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode sentences in the resume and job description\n",
    "resume_embeddings = model.encode(flat_resume_sentences)\n",
    "job_description_embeddings = model.encode(flat_job_description_sentences)\n",
    "\n",
    "# Compute the mean of the sentence embeddings to get a document-level embedding\n",
    "resume_embedding = np.mean(resume_embeddings, axis=0)\n",
    "job_description_embedding = np.mean(job_description_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6315ded7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resume_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity between the resume and job description embeddings\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m similarity_score \u001b[38;5;241m=\u001b[39m cosine_similarity([\u001b[43mresume_embedding\u001b[49m], [job_description_embedding])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resume_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "# METHOD 1 (STS): Similarity score based on SentenceTransformer.\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity between the resume and job description embeddings\n",
    "similarity_score = cosine_similarity([resume_embedding], [job_description_embedding])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff98f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Tokens: ['deepank', 'singh', 'final', 'year', ',', 'information', 'technology', '+91-8168053394', 'deepanksingh01gmail.com', 'linkedin', 'github', 'education', 'rajiv', 'gandhi', 'institute', 'petroleum', 'technology', '(', 'rgipt', ')']\n",
      "\n",
      "\n",
      "Job Description Tokens: ['deepank', 'singh', 'final', 'year', ',', 'information', 'technology', '+91-8168053394', 'deepanksingh01gmail.com', 'linkedin', 'github', 'education', 'rajiv', 'gandhi', 'institute', 'petroleum', 'technology', '(', 'rgipt', ')']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to preprocess text in Dictionary method\n",
    "def preprocess_text_dic(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Regex filter\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s'-.]\", '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Assuming resume_text contains your resume text and jd_file is the path to your JD PDF\n",
    "\n",
    "# For the resume\n",
    "resume_tokens = preprocess_text_dic(resume_text)\n",
    "\n",
    "# For the job description\n",
    "jd_text = extract_text_from_pdf(jd_file)\n",
    "job_desc_tokens = preprocess_text_dic(jd_text)\n",
    "\n",
    "print(\"Resume Tokens:\", resume_tokens[:20])  # Print first 20 tokens\n",
    "print(\"\\n\")\n",
    "print(\"Job Description Tokens:\", job_desc_tokens[:20])  # Print first 20 tokens\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75df1ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8005f325",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb5 in position 11: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#section 2: Identify skills. Dic() method\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m skills_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m skills_df \u001b[38;5;241m=\u001b[39m skills_df\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m      8\u001b[0m skills_list \u001b[38;5;241m=\u001b[39m skills_df[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    664\u001b[0m     dialect,\n\u001b[0;32m    665\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    675\u001b[0m )\n\u001b[0;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1234\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:544\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:749\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb5 in position 11: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "#section 2: Identify skills. Dic() method\n",
    "\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "skills_df = pd.read_csv(filename, header=None)\n",
    "skills_df = skills_df.transpose()\n",
    "skills_list = skills_df[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce755e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract skills\n",
    "def extract_skills(tokens, skills_list):\n",
    "    return [token for token in tokens if token in skills_list]\n",
    "\n",
    "resume_skills = set(extract_skills(resume_tokens[0], skills_list))\n",
    "job_desc_skills = set(extract_skills(job_desc_tokens[0], skills_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-token improvisation using n-grams.\n",
    "\n",
    "def generate_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "\n",
    "def get_all_ngrams(tokens, max_n):\n",
    "    all_ngrams = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        all_ngrams.extend(generate_ngrams(tokens, n))\n",
    "    return all_ngrams\n",
    "\n",
    "\n",
    "def match_keywords(tokens, keywords, max_n=3):\n",
    "    all_ngrams = get_all_ngrams(tokens, max_n)\n",
    "    matches = []\n",
    "    for ngram in all_ngrams:\n",
    "        phrase = ' '.join(ngram)\n",
    "        if phrase in keywords:\n",
    "            matches.append(phrase)\n",
    "    return matches\n",
    "\n",
    "\n",
    "resume_matches = set(match_keywords(resume_tokens[0], skills_list, max_n=3))\n",
    "job_desc_matches = set(match_keywords(job_desc_tokens[0], skills_list, max_n=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#section final: Calculate matching percentage. Dic() method.\n",
    "\n",
    "# Function to calculate matching percentage\n",
    "def calculate_matching_percentage(resume_skills, job_desc_skills):\n",
    "    match_count = len(set(resume_skills) & set(job_desc_skills))\n",
    "    total_skills = len(set(job_desc_skills))\n",
    "    if total_skills == 0:\n",
    "        return 0\n",
    "    return (match_count / total_skills) * 100\n",
    "\n",
    "matching_percentage = calculate_matching_percentage(resume_skills, job_desc_skills)\n",
    "\n",
    "matching_percentage = calculate_matching_percentage(resume_matches, job_desc_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5eb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 3 (STS): Similarity Score using actual CrossEncoder model.\n",
    "from sentence_transformers import CrossEncoder\n",
    "# Load pre-trained Cross-Encoder model\n",
    "model_cross = CrossEncoder('cross-encoder/stsb-roberta-base')\n",
    "\n",
    "# Create input pairs\n",
    "input_pairs = [[jd_sentence, resume_sentence] for jd_sentence in flat_job_description_sentences for resume_sentence in flat_resume_sentences]\n",
    "\n",
    "# Predict similarity scores\n",
    "similarity_scores = model_cross.predict(input_pairs)\n",
    "\n",
    "# Calculate the mean similarity score\n",
    "mean_similarity = similarity_scores.mean()\n",
    "\n",
    "# Reshape the scores into a matrix\n",
    "similarity_matrix = np.reshape(similarity_scores, (len(flat_job_description_sentences), len(flat_resume_sentences)))\n",
    "\n",
    "# Create a DataFrame to hold the similarity matrix\n",
    "similarity_df = pd.DataFrame(similarity_matrix,\n",
    "                             index=[f\"JD Sentence {i+1}\" for i in range(len(flat_job_description_sentences))],\n",
    "                             columns=[f\"Resume Sentence {i+1}\" for i in range(len(flat_resume_sentences))])\n",
    "\n",
    "# Display the DataFrame\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Formula for calculating final STS score. (scaled upto 20)\n",
    "\n",
    "# 1. Mean Similarity Score using CrossEncoder. (scaled upto 10)\n",
    "# 2. Matching percentage of multi-token using Dictionary method. (scaled upto 10)\n",
    "\n",
    "normalized_mean_similarity_score = (mean_similarity*2)  # Assuming the model scores between 0 and 5.\n",
    "\n",
    "normalized_matching_percentage = (matching_percentage/10)\n",
    "\n",
    "# Calculate the combined score (CS) out of 20\n",
    "combined_score = normalized_mean_similarity_score + normalized_matching_percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ada9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine match quality based on combined score\n",
    "\n",
    "\n",
    "\n",
    "# final output of the file only \n",
    "\n",
    "\n",
    "if combined_score >= 16:\n",
    "    match_quality = \"Strong match\"\n",
    "elif 12 <= combined_score < 16:\n",
    "    match_quality = \"Good match\"\n",
    "elif 8 <= combined_score < 12:\n",
    "    match_quality = \"Moderate match\"\n",
    "else:\n",
    "    match_quality = \"Weak match\"\n",
    "\n",
    "print(f\"Match Quality: {match_quality}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
